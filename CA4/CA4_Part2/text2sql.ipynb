{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "36ca5ad4",
      "metadata": {
        "id": "36ca5ad4"
      },
      "source": [
        "## CA 4 - Part 2, LLMs Spring 2025\n",
        "\n",
        "- **Name:**\n",
        "- **Student ID:**\n",
        "\n",
        "---\n",
        "#### Your submission should be named using the following format: `CA4_LASTNAME_STUDENTID.ipynb`.\n",
        "\n",
        "---\n",
        "\n",
        "TA Email: miladmohammadi@ut.ac.ir\n",
        "\n",
        "##### *How to do this problem set:*\n",
        "\n",
        "- Some questions require writing Python code and computing results, and the rest of them have written answers. For coding problems, you will have to fill out all code blocks that say `YOUR CODE HERE`.\n",
        "\n",
        "- For text-based answers, you should replace the text that says ```Your Answer Here``` with your actual answer.\n",
        "\n",
        "- There is no penalty for using AI assistance on this homework as long as you fully disclose it in the final cell of this notebook (this includes storing any prompts that you feed to large language models). That said, anyone caught using AI assistance without proper disclosure will receive a zero on the assignment (we have several automatic tools to detect such cases). We're literally allowing you to use it with no limitations, so there is no reason to lie!\n",
        "\n",
        "---\n",
        "\n",
        "##### *Academic honesty*\n",
        "\n",
        "- We will audit the Colab notebooks from a set number of students, chosen at random. The audits will check that the code you wrote actually generates the answers in your notebook. If you turn in correct answers on your notebook without code that actually generates those answers, we will consider this a serious case of cheating.\n",
        "\n",
        "- We will also run automatic checks of Colab notebooks for plagiarism. Copying code from others is also considered a serious case of cheating.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d86cccf5",
      "metadata": {
        "id": "d86cccf5"
      },
      "source": [
        "## Text2SQL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97c97a10",
      "metadata": {
        "id": "97c97a10"
      },
      "source": [
        "In this section, you will progressively build and evaluate multiple Text-to-SQL pipelines. You’ll start with a simple prompting-based baseline, then design a graph-based routing system using chain-of-thought and schema reasoning, and finally construct a ReAct agent that interacts with the schema via tools. Each stage demonstrates a different strategy for generating SQL from natural language using LLMs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86892463",
      "metadata": {
        "id": "86892463"
      },
      "source": [
        "### Initializations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e367a33b",
      "metadata": {
        "id": "e367a33b"
      },
      "source": [
        "This section prepares the environment and initializes the LLM model (Gemini) to be used in later parts of the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "079d57ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "079d57ea",
        "outputId": "cc4faeb2-b008-45db-cc13-b72730cfeefb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from -r requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: langchain in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from -r requirements.txt (line 2)) (0.3.27)\n",
            "Requirement already satisfied: langgraph in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from -r requirements.txt (line 3)) (0.6.1)\n",
            "Requirement already satisfied: langchain-core in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from -r requirements.txt (line 4)) (0.3.72)\n",
            "Requirement already satisfied: langchain-google-genai in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from -r requirements.txt (line 5)) (2.1.8)\n",
            "Requirement already satisfied: tqdm in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from -r requirements.txt (line 6)) (4.67.1)\n",
            "Requirement already satisfied: pandas in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from -r requirements.txt (line 7)) (2.2.3)\n",
            "Requirement already satisfied: func-timeout in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from -r requirements.txt (line 8)) (4.3.5)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (0.4.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (2.0.42)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langgraph->-r requirements.txt (line 3)) (2.1.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langgraph->-r requirements.txt (line 3)) (0.6.1)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.0 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langgraph->-r requirements.txt (line 3)) (0.2.0)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langgraph->-r requirements.txt (line 3)) (3.5.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langchain-core->-r requirements.txt (line 4)) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langchain-core->-r requirements.txt (line 4)) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langchain-core->-r requirements.txt (line 4)) (4.12.2)\n",
            "Requirement already satisfied: packaging>=23.2 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langchain-core->-r requirements.txt (line 4)) (24.2)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langchain-google-genai->-r requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langchain-google-genai->-r requirements.txt (line 5)) (0.6.18)\n",
            "Requirement already satisfied: colorama in c:\\users\\sazgar\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->-r requirements.txt (line 6)) (0.4.6)\n",
            "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from pandas->-r requirements.txt (line 7)) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from pandas->-r requirements.txt (line 7)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from pandas->-r requirements.txt (line 7)) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from pandas->-r requirements.txt (line 7)) (2025.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 5)) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 5)) (2.40.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 5)) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 5)) (6.31.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core->-r requirements.txt (line 4)) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph->-r requirements.txt (line 3)) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph->-r requirements.txt (line 3)) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph->-r requirements.txt (line 3)) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langsmith>=0.1.17->langchain->-r requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langsmith>=0.1.17->langchain->-r requirements.txt (line 2)) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 2)) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 2)) (3.2.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 5)) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 5)) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 5)) (1.74.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 5)) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 5)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 5)) (4.9.1)\n",
            "Requirement already satisfied: anyio in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph->-r requirements.txt (line 3)) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph->-r requirements.txt (line 3)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph->-r requirements.txt (line 3)) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 5)) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph->-r requirements.txt (line 3)) (1.3.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7c5bc3b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import re\n",
        "\n",
        "from typing import Literal, Optional #\n",
        "from pydantic import BaseModel, Field #\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI # برای llm\n",
        "from langchain_core.messages import SystemMessage, HumanMessage #\n",
        "from langchain_core.prompts import ChatPromptTemplate #\n",
        "from langchain_core.runnables import Runnable #\n",
        "\n",
        "from langgraph.graph import MessagesState, StateGraph, START"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d9f4a2c",
      "metadata": {
        "id": "9d9f4a2c"
      },
      "source": [
        "#### Load API Key (2 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "684e23a1",
      "metadata": {
        "id": "684e23a1"
      },
      "source": [
        "**Task:** Load the Gemini API key stored in the `.env` file and set it as an environment variable so it can be used to authenticate API requests later.\n",
        "\n",
        "* Use `dotenv` to load the file.\n",
        "* Extract the API key with `os.getenv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cd477695",
      "metadata": {
        "id": "cd477695"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
        "if not GOOGLE_API_KEY:\n",
        "  raise ValueError(\"GOOGLE_API_KEY not found in .env file or environment variable\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87ce1714",
      "metadata": {
        "id": "87ce1714"
      },
      "source": [
        "#### Create ChatModel (3 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b50a6f5",
      "metadata": {
        "id": "3b50a6f5"
      },
      "source": [
        "**Task:** Create an instance of the Gemini LLM using LangChain. You should configure the model with proper parameters for our task.\n",
        "\n",
        "Note: You may use any model that supports Structured Output and Tool Use. We recommend using gemini-2.5-flash-preview-05-20 from Google AI Studio, as it offers a generous free tier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c117040d",
      "metadata": {
        "id": "c117040d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sazgar\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3553: UserWarning: Parameters {'max_output_tokens', 'temperature', 'model'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "gemini_param = {\n",
        "    \"model\": \"gemini-2.5-flash-preview-05-20\",\n",
        "    \"temperature\": 0.01,\n",
        "    \"max_output_tokens\": 512,\n",
        "\n",
        "}\n",
        "# Create an instance of the Gemini LLM\n",
        "llm = ChatGoogleGenerativeAI(model_kwargs=gemini_param, google_api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "NQCVD1nBlndW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQCVD1nBlndW",
        "outputId": "79d6ad12-5692-450d-da27-e0a9f449f080"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Meow!\n"
          ]
        }
      ],
      "source": [
        "response = llm.invoke(\"just say Meow!\")\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8440112",
      "metadata": {
        "id": "e8440112"
      },
      "source": [
        "### Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "588c1c0b",
      "metadata": {
        "id": "588c1c0b"
      },
      "source": [
        "In this section, you'll build a simple baseline pipeline that directly converts a question and schema into a SQL query using a single prompt."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abef3ecf",
      "metadata": {
        "id": "abef3ecf"
      },
      "source": [
        "#### Baseline Function (5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7452b396",
      "metadata": {
        "id": "7452b396"
      },
      "source": [
        "\n",
        "**Task:** Implement a function that sends a system message defining the task, and a user message containing the input question and schema. The LLM should return the SQL query formatted as: \"```sql\\n[query]```\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "id": "0fd0eb1c",
      "metadata": {
        "id": "0fd0eb1c"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "def run_baseline(question: str, schema: str):\n",
        "    sys_msg = \"\"\"\n",
        "    ### TASK DESCRIPTION\n",
        "    You are an expert systems that receives a user's question and a database schema. \\\n",
        "    Generate a SQL query that answers the question.\n",
        "\n",
        "    ### FORMAT\n",
        "    formatted as a markdown SQL code block:\\n\n",
        "    ```sql\n",
        "    [query]\n",
        "    ```\n",
        "    \"\"\"\n",
        "    user_msg = f\"\"\"\n",
        "    Question: {question}\\n\n",
        "    Schema:\\n{schema}\\n\n",
        "    Only generate the SQL query, nothing else.\n",
        "    \"\"\"\n",
        "\n",
        "    messages = [\n",
        "        SystemMessage(content=sys_msg),\n",
        "        HumanMessage(content=user_msg)\n",
        "    ]\n",
        "\n",
        "    response = llm.invoke(messages)\n",
        "    sql_query = response.content\n",
        "\n",
        "    return sql_query"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b335cbd8",
      "metadata": {
        "id": "b335cbd8"
      },
      "source": [
        "#### Run and Evaluate (Estimated Run Time 5-10min)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f328a0c2",
      "metadata": {
        "id": "f328a0c2"
      },
      "source": [
        "Run your baseline function over the dataset provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "538878ae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "538878ae",
        "outputId": "74a7c6aa-214d-4b94-a9c2-713a23d27469"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/18 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Find the percentage of atoms with single bond. (Evidence: single bond refers to bond_type = '-'; percentage = DIVIDE(SUM(bond_type = '-'), COUNT(bond_id)) as percentage)\n",
            "Schema: atom (atom_id, molecule_id, element)\n",
            "bond (bond_id, molecule_id, bond_type)\n",
            "connected (atom_id, atom_id2, bond_id)\n",
            "molecule (molecule_id, label)\n",
            "\n",
            "Generated SQL: SELECT\n",
            "  CAST(SUM(CASE WHEN bond_type = '-' THEN 1 ELSE 0 END) AS REAL) * 100 / COUNT(bond_id)\n",
            "FROM bond;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 1/18 [00:11<03:09, 11.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Indicate which atoms are connected in non-carcinogenic type molecules. (Evidence: label = '-' means molecules are non-carcinogenic)\n",
            "Schema: atom (atom_id, molecule_id, element)\n",
            "bond (bond_id, molecule_id, bond_type)\n",
            "connected (atom_id, atom_id2, bond_id)\n",
            "molecule (molecule_id, label)\n",
            "\n",
            "Generated SQL: SELECT\n",
            "  T1.atom_id,\n",
            "  T1.atom_id2\n",
            "FROM connected AS T1\n",
            "INNER JOIN bond AS T2\n",
            "  ON T1.bond_id = T2.bond_id\n",
            "INNER JOIN molecule AS T3\n",
            "  ON T2.molecule_id = T3.molecule_id\n",
            "WHERE\n",
            "  T3.label = '-';\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 2/18 [00:23<03:06, 11.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What is the average number of bonds the atoms with the element iodine have? (Evidence: atoms with the element iodine refers to element = 'i'; average = DIVIDE(COUND(bond_id), COUNT(atom_id)) where element = 'i')\n",
            "Schema: atom (atom_id, molecule_id, element)\n",
            "bond (bond_id, molecule_id, bond_type)\n",
            "connected (atom_id, atom_id2, bond_id)\n",
            "molecule (molecule_id, label)\n",
            "\n",
            "Generated SQL: \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 3/18 [00:36<03:03, 12.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: List down two molecule id of triple bond non carcinogenic molecules with element carbon. (Evidence: carbon refers to element = 'c'; triple bond refers to bond_type = '#'; label = '-' means molecules are non-carcinogenic)\n",
            "Schema: atom (atom_id, molecule_id, element)\n",
            "bond (bond_id, molecule_id, bond_type)\n",
            "connected (atom_id, atom_id2, bond_id)\n",
            "molecule (molecule_id, label)\n",
            "\n",
            "Generated SQL: SELECT DISTINCT\n",
            "  T1.molecule_id\n",
            "FROM molecule AS T1\n",
            "INNER JOIN bond AS T2\n",
            "  ON T1.molecule_id = T2.molecule_id\n",
            "INNER JOIN atom AS T3\n",
            "  ON T1.molecule_id = T3.molecule_id\n",
            "WHERE\n",
            "  T2.bond_type = '#' AND T3.element = 'c' AND T1.label = '-'\n",
            "LIMIT 2;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 4/18 [00:47<02:49, 12.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What are the elements of the toxicology and label of molecule TR060? (Evidence: TR060 is the molecule id; label = '+' mean molecules are carcinogenic; label = '-' means molecules are non-carcinogenic; element = 'cl' means Chlorine; element = 'c' means Carbon; element = 'h' means Hydrogen; element = 'o' means Oxygen, element = 's' means Sulfur; element = 'n' means Nitrogen, element = 'p' means Phosphorus, element = 'na' means Sodium, element = 'br' means Bromine, element = 'f' means Fluorine; element = 'i' means Iodine; element = 'sn' means Tin; element = 'pb' means Lead; element = 'te' means Tellurium; element = 'ca' means Calcium)\n",
            "Schema: atom (atom_id, molecule_id, element)\n",
            "bond (bond_id, molecule_id, bond_type)\n",
            "connected (atom_id, atom_id2, bond_id)\n",
            "molecule (molecule_id, label)\n",
            "\n",
            "Generated SQL: SELECT T1.element, T2.label\n",
            "FROM atom AS T1\n",
            "INNER JOIN molecule AS T2\n",
            "  ON T1.molecule_id = T2.molecule_id\n",
            "WHERE\n",
            "  T1.molecule_id = 'TR060';\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 5/18 [00:58<02:32, 11.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What are the elements for bond id TR001_10_11? (Evidence: element = 'cl' means Chlorine; element = 'c' means Carbon; element = 'h' means Hydrogen; element = 'o' means Oxygen, element = 's' means Sulfur; element = 'n' means Nitrogen, element = 'p' means Phosphorus, element = 'na' means Sodium, element = 'br' means Bromine, element = 'f' means Fluorine; element = 'i' means Iodine; element = 'sn' means Tin; element = 'pb' means Lead; element = 'te' means Tellurium; element = 'ca' means Calcium)\n",
            "Schema: atom (atom_id, molecule_id, element)\n",
            "bond (bond_id, molecule_id, bond_type)\n",
            "connected (atom_id, atom_id2, bond_id)\n",
            "molecule (molecule_id, label)\n",
            "\n",
            "Generated SQL: SELECT DISTINCT T3.element\n",
            "FROM bond AS T1\n",
            "INNER JOIN connected AS T2\n",
            "  ON T1.bond_id = T2.bond_id\n",
            "INNER JOIN atom AS T3\n",
            "  ON T2.atom_id = T3.atom_id OR T2.atom_id2 = T3.atom_id\n",
            "WHERE\n",
            "  T1.bond_id = 'TR001_10_11';\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 6/18 [01:12<02:27, 12.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: How many superheroes were published by Dark Horse Comics? (Evidence: published by Dark Horse Comics refers to publisher_name = 'Dark Horse Comics';)\n",
            "Schema: alignment (id, alignment)\n",
            "attribute (id, attribute_name)\n",
            "colour (id, colour)\n",
            "gender (id, gender)\n",
            "publisher (id, publisher_name)\n",
            "race (id, race)\n",
            "superhero (id, superhero_name, full_name, gender_id, eye_colour_id, hair_colour_id, skin_colour_id, race_id, publisher_id, alignment_id, height_cm, weight_kg)\n",
            "hero_attribute (hero_id, attribute_id, attribute_value)\n",
            "superpower (id, power_name)\n",
            "hero_power (hero_id, power_id)\n",
            "\n",
            "Generated SQL: SELECT\n",
            "  COUNT(s.id)\n",
            "FROM superhero AS s\n",
            "JOIN publisher AS p\n",
            "  ON s.publisher_id = p.id\n",
            "WHERE\n",
            "  p.publisher_name = 'Dark Horse Comics';\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▉      | 7/18 [01:23<02:10, 11.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What are the race and alignment of Cameron Hicks? (Evidence: Cameron Hicks refers to superhero_name = 'Cameron Hicks';)\n",
            "Schema: alignment (id, alignment)\n",
            "attribute (id, attribute_name)\n",
            "colour (id, colour)\n",
            "gender (id, gender)\n",
            "publisher (id, publisher_name)\n",
            "race (id, race)\n",
            "superhero (id, superhero_name, full_name, gender_id, eye_colour_id, hair_colour_id, skin_colour_id, race_id, publisher_id, alignment_id, height_cm, weight_kg)\n",
            "hero_attribute (hero_id, attribute_id, attribute_value)\n",
            "superpower (id, power_name)\n",
            "hero_power (hero_id, power_id)\n",
            "\n",
            "Generated SQL: SELECT\n",
            "  T2.race,\n",
            "  T3.alignment\n",
            "FROM superhero AS T1\n",
            "INNER JOIN race AS T2\n",
            "ON T1.race_id = T2.id\n",
            "INNER JOIN alignment AS T3\n",
            "ON T1.alignment_id = T3.id\n",
            "WHERE\n",
            "  T1.superhero_name = 'Cameron Hicks';\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 8/18 [01:35<01:58, 11.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Among the superheroes with height from 170 to 190, list the names of the superheroes with no eye color. (Evidence: height from 170 to 190 refers to height_cm BETWEEN 170 AND 190; no eye color refers to eye_colour_id = 1)\n",
            "Schema: alignment (id, alignment)\n",
            "attribute (id, attribute_name)\n",
            "colour (id, colour)\n",
            "gender (id, gender)\n",
            "publisher (id, publisher_name)\n",
            "race (id, race)\n",
            "superhero (id, superhero_name, full_name, gender_id, eye_colour_id, hair_colour_id, skin_colour_id, race_id, publisher_id, alignment_id, height_cm, weight_kg)\n",
            "hero_attribute (hero_id, attribute_id, attribute_value)\n",
            "superpower (id, power_name)\n",
            "hero_power (hero_id, power_id)\n",
            "\n",
            "Generated SQL: SELECT superhero_name\n",
            "FROM superhero\n",
            "WHERE height_cm BETWEEN 170 AND 190 AND eye_colour_id = 1;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 9/18 [01:46<01:45, 11.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: List down at least five superpowers of male superheroes. (Evidence: male refers to gender = 'Male'; superpowers refers to power_name;)\n",
            "Schema: alignment (id, alignment)\n",
            "attribute (id, attribute_name)\n",
            "colour (id, colour)\n",
            "gender (id, gender)\n",
            "publisher (id, publisher_name)\n",
            "race (id, race)\n",
            "superhero (id, superhero_name, full_name, gender_id, eye_colour_id, hair_colour_id, skin_colour_id, race_id, publisher_id, alignment_id, height_cm, weight_kg)\n",
            "hero_attribute (hero_id, attribute_id, attribute_value)\n",
            "superpower (id, power_name)\n",
            "hero_power (hero_id, power_id)\n",
            "\n",
            "Generated SQL: SELECT DISTINCT\n",
            "  sp.power_name\n",
            "FROM superpower AS sp\n",
            "JOIN hero_power AS hp\n",
            "  ON sp.id = hp.power_id\n",
            "JOIN superhero AS sh\n",
            "  ON hp.hero_id = sh.id\n",
            "JOIN gender AS g\n",
            "  ON sh.gender_id = g.id\n",
            "WHERE\n",
            "  g.gender = 'Male'\n",
            "LIMIT 5;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 10/18 [01:58<01:32, 11.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What is the percentage of superheroes who act in their own self-interest or make decisions based on their own moral code? Indicate how many of the said superheroes were published by Marvel Comics. (Evidence: published by Marvel Comics refers to publisher_name = 'Marvel Comics'; superheroes who act in their own self-interest or make decisions based on their own moral code refers to alignment = 'Bad'; calculation = MULTIPLY(DIVIDE(SUM(alignment = 'Bad); count(id)), 100))\n",
            "Schema: alignment (id, alignment)\n",
            "attribute (id, attribute_name)\n",
            "colour (id, colour)\n",
            "gender (id, gender)\n",
            "publisher (id, publisher_name)\n",
            "race (id, race)\n",
            "superhero (id, superhero_name, full_name, gender_id, eye_colour_id, hair_colour_id, skin_colour_id, race_id, publisher_id, alignment_id, height_cm, weight_kg)\n",
            "hero_attribute (hero_id, attribute_id, attribute_value)\n",
            "superpower (id, power_name)\n",
            "hero_power (hero_id, power_id)\n",
            "\n",
            "Generated SQL: SELECT\n",
            "  (\n",
            "    COUNT(CASE WHEN T2.alignment = 'Bad' THEN T1.id END) * 100.0\n",
            "  ) / COUNT(T1.id) AS percentage_bad_alignment,\n",
            "  COUNT(\n",
            "    CASE WHEN T2.alignment = 'Bad' AND T3.publisher_name = 'Marvel Comics' THEN T1.id END\n",
            "  ) AS marvel_bad_alignment_count\n",
            "FROM superhero AS T1\n",
            "INNER JOIN alignment AS T2\n",
            "  ON T1.alignment_id = T2.id\n",
            "LEFT JOIN publisher AS T3\n",
            "  ON T1.publisher_id = T3.id;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████    | 11/18 [02:11<01:25, 12.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Which publisher created more superheroes: DC or Marvel Comics? Find the difference in the number of superheroes. (Evidence: DC refers to publisher_name = 'DC Comics'; Marvel Comics refers to publisher_name = 'Marvel Comics'; if SUM(publisher_name = 'DC Comics') > SUM(publisher_name = 'Marvel Comics'), it means DC Comics published more superheroes than Marvel Comics; if SUM(publisher_name = 'Marvel Comics') > SUM(publisher_name = 'Marvel Comics'), it means Marvel Comics published more heroes than DC Comics; difference = SUBTRACT(SUM(publisher_name = 'DC Comics'), SUM(publisher_name = 'Marvel Comics'));)\n",
            "Schema: alignment (id, alignment)\n",
            "attribute (id, attribute_name)\n",
            "colour (id, colour)\n",
            "gender (id, gender)\n",
            "publisher (id, publisher_name)\n",
            "race (id, race)\n",
            "superhero (id, superhero_name, full_name, gender_id, eye_colour_id, hair_colour_id, skin_colour_id, race_id, publisher_id, alignment_id, height_cm, weight_kg)\n",
            "hero_attribute (hero_id, attribute_id, attribute_value)\n",
            "superpower (id, power_name)\n",
            "hero_power (hero_id, power_id)\n",
            "\n",
            "Generated SQL: \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 12/18 [02:24<01:14, 12.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Who was the first one paid his/her dues? Tell the full name. (Evidence: full name refers to first_name, last_name; first paid dues refers to MIN(received_date) where source = 'Dues')\n",
            "Schema: event (event_id, event_name, event_date, type, notes, location, status)\n",
            "major (major_id, major_name, department, college)\n",
            "zip_code (zip_code, type, city, county, state, short_state)\n",
            "attendance (link_to_event, link_to_member)\n",
            "budget (budget_id, category, spent, remaining, amount, event_status, link_to_event)\n",
            "expense (expense_id, expense_description, expense_date, cost, approved, link_to_member, link_to_budget)\n",
            "income (income_id, date_received, amount, source, notes, link_to_member)\n",
            "member (member_id, first_name, last_name, email, position, t_shirt_size, phone, zip, link_to_major)\n",
            "\n",
            "Generated SQL: SELECT\n",
            "  T1.first_name,\n",
            "  T1.last_name\n",
            "FROM member AS T1\n",
            "INNER JOIN income AS T2\n",
            "  ON T1.member_id = T2.link_to_member\n",
            "WHERE\n",
            "  T2.source = 'Dues' AND T2.date_received = (\n",
            "    SELECT\n",
            "      MIN(date_received)\n",
            "    FROM income\n",
            "    WHERE\n",
            "      source = 'Dues'\n",
            "  );\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 13/18 [02:37<01:02, 12.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: How many income are received with an amount of 50? (Evidence: amount of 50 refers to amount = 50)\n",
            "Schema: event (event_id, event_name, event_date, type, notes, location, status)\n",
            "major (major_id, major_name, department, college)\n",
            "zip_code (zip_code, type, city, county, state, short_state)\n",
            "attendance (link_to_event, link_to_member)\n",
            "budget (budget_id, category, spent, remaining, amount, event_status, link_to_event)\n",
            "expense (expense_id, expense_description, expense_date, cost, approved, link_to_member, link_to_budget)\n",
            "income (income_id, date_received, amount, source, notes, link_to_member)\n",
            "member (member_id, first_name, last_name, email, position, t_shirt_size, phone, zip, link_to_major)\n",
            "\n",
            "Generated SQL: SELECT\n",
            "  COUNT(income_id)\n",
            "FROM income\n",
            "WHERE\n",
            "  amount = 50;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 14/18 [02:48<00:48, 12.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Name the event with the highest amount spent on advertisement. (Evidence: event refers to event_name; highest amount spent on advertisement refers to MAX(spent) where category = 'Advertisement')\n",
            "Schema: event (event_id, event_name, event_date, type, notes, location, status)\n",
            "major (major_id, major_name, department, college)\n",
            "zip_code (zip_code, type, city, county, state, short_state)\n",
            "attendance (link_to_event, link_to_member)\n",
            "budget (budget_id, category, spent, remaining, amount, event_status, link_to_event)\n",
            "expense (expense_id, expense_description, expense_date, cost, approved, link_to_member, link_to_budget)\n",
            "income (income_id, date_received, amount, source, notes, link_to_member)\n",
            "member (member_id, first_name, last_name, email, position, t_shirt_size, phone, zip, link_to_major)\n",
            "\n",
            "Generated SQL: SELECT\n",
            "  T1.event_name\n",
            "FROM event AS T1\n",
            "INNER JOIN budget AS T2\n",
            "  ON T1.event_id = T2.link_to_event\n",
            "WHERE\n",
            "  T2.category = 'Advertisement'\n",
            "ORDER BY\n",
            "  T2.spent DESC\n",
            "LIMIT 1;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 15/18 [02:59<00:35, 11.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Based on the total cost for all event, what is the percentage of cost for Yearly Kickoff event? (Evidence: DIVIDE(SUM(cost where event_name = 'Yearly Kickoff'), SUM(cost)) * 100)\n",
            "Schema: event (event_id, event_name, event_date, type, notes, location, status)\n",
            "major (major_id, major_name, department, college)\n",
            "zip_code (zip_code, type, city, county, state, short_state)\n",
            "attendance (link_to_event, link_to_member)\n",
            "budget (budget_id, category, spent, remaining, amount, event_status, link_to_event)\n",
            "expense (expense_id, expense_description, expense_date, cost, approved, link_to_member, link_to_budget)\n",
            "income (income_id, date_received, amount, source, notes, link_to_member)\n",
            "member (member_id, first_name, last_name, email, position, t_shirt_size, phone, zip, link_to_major)\n",
            "\n",
            "Generated SQL: SELECT\n",
            "  SUM(CASE WHEN T3.event_name = 'Yearly Kickoff' THEN T1.cost ELSE 0 END) * 100.0 / SUM(T1.cost)\n",
            "FROM expense AS T1\n",
            "INNER JOIN budget AS T2\n",
            "  ON T1.link_to_budget = T2.budget_id\n",
            "INNER JOIN event AS T3\n",
            "  ON T2.link_to_event = T3.event_id;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 89%|████████▉ | 16/18 [03:11<00:23, 11.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Calculate the total average cost that Elijah Allen spent in the events on September and October. (Evidence: events in September and October refers to month(expense_date) = 9 AND MONTH(expense_date) = 10)\n",
            "Schema: event (event_id, event_name, event_date, type, notes, location, status)\n",
            "major (major_id, major_name, department, college)\n",
            "zip_code (zip_code, type, city, county, state, short_state)\n",
            "attendance (link_to_event, link_to_member)\n",
            "budget (budget_id, category, spent, remaining, amount, event_status, link_to_event)\n",
            "expense (expense_id, expense_description, expense_date, cost, approved, link_to_member, link_to_budget)\n",
            "income (income_id, date_received, amount, source, notes, link_to_member)\n",
            "member (member_id, first_name, last_name, email, position, t_shirt_size, phone, zip, link_to_major)\n",
            "\n",
            "Generated SQL: SELECT\n",
            "  AVG(T1.cost)\n",
            "FROM expense AS T1\n",
            "INNER JOIN member AS T2\n",
            "  ON T1.link_to_member = T2.member_id\n",
            "WHERE\n",
            "  T2.first_name = 'Elijah' AND T2.last_name = 'Allen' AND (\n",
            "    STRFTIME('%m', T1.expense_date) = '09' OR STRFTIME('%m', T1.expense_date) = '10'\n",
            "  );\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 17/18 [03:23<00:11, 11.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Find the name and date of events with expenses for pizza that were more than fifty dollars but less than a hundred dollars. (Evidence: name of event refers to event_name; date of event refers to event_date; expenses for pizza refers to expense_description = 'Pizza' where cost > 50 and cost < 100)\n",
            "Schema: event (event_id, event_name, event_date, type, notes, location, status)\n",
            "major (major_id, major_name, department, college)\n",
            "zip_code (zip_code, type, city, county, state, short_state)\n",
            "attendance (link_to_event, link_to_member)\n",
            "budget (budget_id, category, spent, remaining, amount, event_status, link_to_event)\n",
            "expense (expense_id, expense_description, expense_date, cost, approved, link_to_member, link_to_budget)\n",
            "income (income_id, date_received, amount, source, notes, link_to_member)\n",
            "member (member_id, first_name, last_name, email, position, t_shirt_size, phone, zip, link_to_major)\n",
            "\n",
            "Generated SQL: SELECT\n",
            "  T1.event_name,\n",
            "  T1.event_date\n",
            "FROM event AS T1\n",
            "INNER JOIN budget AS T2\n",
            "  ON T1.event_id = T2.link_to_event\n",
            "INNER JOIN expense AS T3\n",
            "  ON T2.budget_id = T3.link_to_budget\n",
            "WHERE\n",
            "  T3.expense_description = 'Pizza' AND T3.cost > 50 AND T3.cost < 100;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [03:35<00:00, 11.95s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting to compare without knowledge for ex\n",
            "Process finished successfully\n",
            "start calculate\n",
            "                     simple               moderate             challenging          total               \n",
            "count                6                    6                    6                    18                  \n",
            "======================================    ACCURACY    =====================================\n",
            "accuracy             66.67                83.33                83.33                77.78               \n",
            "===========================================================================================\n",
            "Finished evaluation\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from method_run import run_method\n",
        "import re\n",
        "\n",
        "def function_template(item):\n",
        "    result = run_baseline(item['question'], item['schema'])\n",
        "    # First try to extract query from markdown SQL block\n",
        "    match = re.search(r'```sql\\n(.*?)```', result, re.DOTALL)\n",
        "    if match:\n",
        "        query = match.group(1).strip()\n",
        "    else:\n",
        "        # If no markdown block found, try to extract just SQL query\n",
        "        query = result.strip()\n",
        "        # Remove any ```sql or ``` if present without proper formatting\n",
        "        query = re.sub(r'```sql|```', '', query).strip()\n",
        "\n",
        "    print(f\"Question: {item['question']}\")\n",
        "    print(f\"Schema: {item['schema']}\")\n",
        "    print(f\"Generated SQL: {query}\\n\")\n",
        "\n",
        "    return {**item, 'sql': query}\n",
        "\n",
        "run_method(function_template, SLEEP_TIME=10)\n",
        "\n",
        "#Run on mode=nano if you want to test it on a smaller dataset\n",
        "#run_method(function_template, SLEEP_TIME=10, mode=\"nano\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4cd06f9",
      "metadata": {
        "id": "f4cd06f9"
      },
      "source": [
        "### Chain/Router"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f46affa4",
      "metadata": {
        "id": "f46affa4"
      },
      "source": [
        "Here, you will build a more advanced system that routes the query through different paths based on question difficulty. Easier questions go straight to query generation; harder ones go through schema path extraction first."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afa254aa",
      "metadata": {
        "id": "afa254aa"
      },
      "source": [
        "#### Define State (5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a7db5cc",
      "metadata": {
        "id": "6a7db5cc"
      },
      "source": [
        "**Task:** Define a `RouterGraphState` using `MessagesState` and `pydantic` that contains:\n",
        "* The input question and schema\n",
        "* The predicted difficulty level\n",
        "* The extracted schema path\n",
        "* The final query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d65c044e",
      "metadata": {
        "id": "d65c044e"
      },
      "outputs": [],
      "source": [
        "from typing import List, Literal, Optional\n",
        "from langchain_core.messages import BaseMessage\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "class RouterGraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "\n",
        "    Attributes:\n",
        "        question: The user's question.\n",
        "        schema: The database schema.\n",
        "        messages: The list of messages exchanged in the graph.\n",
        "        question_difficulty: The classified difficulty of the question.\n",
        "        reasoning: The reasoning behind the difficulty classification. # <-- اضافه شد\n",
        "        key_factors: Key factors influencing the difficulty. # <-- اضافه شد\n",
        "        schema_path: The relevant schema subset for complex questions.\n",
        "        query: The final generated SQL query.\n",
        "    \"\"\"\n",
        "    question: str\n",
        "    schema: str\n",
        "    messages: List[BaseMessage]\n",
        "    \n",
        "    question_difficulty: Optional[Literal[\"simple\", \"moderate\", \"challenging\"]]\n",
        "    reasoning: Optional[str]        \n",
        "    key_factors: Optional[List[str]]\n",
        "\n",
        "    schema_path: Optional[str]\n",
        "    query: Optional[str]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "696dc1c9",
      "metadata": {
        "id": "696dc1c9"
      },
      "source": [
        "#### Node: Analyser (5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "971ace53",
      "metadata": {
        "id": "971ace53"
      },
      "source": [
        "**Task:** Build a node that:\n",
        "* Accepts a question and schema\n",
        "* Analyzes the difficulty (simple/moderate/challanging)\n",
        "* Uses the LLM’s structured output feature to return the difficulty\n",
        "\n",
        "**Steps**:\n",
        "\n",
        "1. Define a Pydantic class to hold the expected structured output.\n",
        "2. Use structure output mode of LLM to bind it to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "a1969dbc",
      "metadata": {
        "id": "a1969dbc"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class QuestionDifficultyAnalysis(BaseModel):\n",
        "    question_difficulty: Literal[\"simple\", \"moderate\", \"challenging\"] = Field(\n",
        "        ..., description=\"The difficulty level of the question.\"\n",
        "    )\n",
        "    reasoning: str = Field(\n",
        "        ..., description=\"Brief explanation for why this difficulty was assigned.\"\n",
        "    )\n",
        "    key_factors: list[str] = Field(\n",
        "        ..., description=\"List of key factors that influenced the difficulty assessment.\"\n",
        "    )\n",
        "\n",
        "def analyser_node(state: RouterGraphState) -> dict:\n",
        "    \"\"\"\n",
        "    Analyzes the user's question, handles potential failures,\n",
        "    and updates the state with the full analysis.\n",
        "    \"\"\"\n",
        "    print(\"---(1) ANALYZING QUESTION---\")\n",
        "    \n",
        "    prompt = f\"\"\"\n",
        "    Analyze the difficulty of this SQL question based on the database schema provided.\n",
        "\n",
        "    Question: {state['question']}\n",
        "    Schema: {state['schema']}\n",
        "\n",
        "    Consider these factors:\n",
        "    - Simple: Single table queries, basic WHERE conditions.\n",
        "    - Moderate: Joins between 2-3 tables, basic aggregations.\n",
        "    - Challenging: Complex joins, nested queries, advanced aggregations.\n",
        "\n",
        "    Provide your analysis with reasoning and key factors.\n",
        "    \"\"\"\n",
        "    \n",
        "    try:\n",
        "        structured_llm = llm.with_structured_output(QuestionDifficultyAnalysis)\n",
        "        response = structured_llm.invoke(prompt)\n",
        "        \n",
        "        if response is None:\n",
        "            raise ValueError(\"LLM returned a None response without raising an exception.\")\n",
        "\n",
        "        print(\"✅ Analysis successful.\")\n",
        "        return {\n",
        "            \"question_difficulty\": response.question_difficulty,\n",
        "            \"reasoning\": response.reasoning,\n",
        "            \"key_factors\": response.key_factors\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"❌ ERROR during analysis: {e}. Defaulting to 'moderate'.\")\n",
        "        return {\n",
        "            \"question_difficulty\": \"moderate\",\n",
        "            \"reasoning\": f\"LLM analysis failed: {e}. Defaulting.\",\n",
        "            \"key_factors\": [\"LLM_FAILURE\"]\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f78d38c",
      "metadata": {
        "id": "9f78d38c"
      },
      "source": [
        "#### Conditional Edge (2 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "406d17e0",
      "metadata": {
        "id": "406d17e0"
      },
      "source": [
        "**Task:** Implement a branching function that decides whether to proceed to direct query generation or schema path extraction based on the difficulty label returned by the analyser.\n",
        "\n",
        "* If the difficulty is “easy”, go directly to query generation.\n",
        "* Otherwise, extract the schema path first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "908afa3c",
      "metadata": {
        "id": "908afa3c"
      },
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "\n",
        "def is_schema_extraction_needed(state: RouterGraphState) -> Literal[\"schema_path_extractor\", \"query_generator\"]:\n",
        "    \"\"\"\n",
        "    This defensively-coded routing function determines the next step.\n",
        "    It handles missing keys, incorrect types, and empty strings to prevent crashes.\n",
        "    \"\"\"\n",
        "    print(\"---(2) ROUTING DECISION---\")\n",
        "    \n",
        "    difficulty = state.get('question_difficulty')\n",
        "\n",
        "    if difficulty is None:\n",
        "        print(\"⚠️ Difficulty is None. Defaulting to the safer path (schema extraction).\")\n",
        "        return \"schema_path_extractor\"\n",
        "\n",
        "    if not isinstance(difficulty, str):\n",
        "        print(f\"⚠️ ERROR: Expected difficulty to be a string, but got {type(difficulty)}. Defaulting to safer path.\")\n",
        "        return \"schema_path_extractor\"\n",
        "\n",
        "    difficulty_normalized = difficulty.strip().lower()\n",
        "    \n",
        "    if not difficulty_normalized:\n",
        "        print(\"⚠️ Difficulty is an empty string. Defaulting to safer path.\")\n",
        "        return \"schema_path_extractor\"\n",
        "\n",
        "    print(f\"Difficulty is '{difficulty_normalized}'. Deciding next step...\")\n",
        "\n",
        "    if difficulty_normalized == \"simple\":\n",
        "        print(\"✅ Routing to: query_generator\")\n",
        "        return \"query_generator\"\n",
        "    else:\n",
        "        print(\"✅ Routing to: schema_path_extractor\")\n",
        "        return \"schema_path_extractor\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "108c9d25",
      "metadata": {
        "id": "108c9d25"
      },
      "source": [
        "#### Node: Schema Extractor (3 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e159a0f9",
      "metadata": {
        "id": "e159a0f9"
      },
      "source": [
        "**Task:** Implement a node that takes the question and schema and extracts a join path or sequence of relevant tables from the schema based on the question.\n",
        "\n",
        "* Use a simple prompt for this.\n",
        "* Store the result in the `schema_path` field of the state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "598a057f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "SCHEMA_FILTER_PROMPT = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"\"\"\n",
        "You are a hyper-efficient database schema filter. Your SOLE task is to extract the exact, complete `CREATE TABLE` statements for ONLY the tables needed to answer the user's question from the provided full schema.\n",
        "\n",
        "### RULES:\n",
        "1.  **Analyze the Question:** Identify all entities and relationships mentioned or implied in the user's question.\n",
        "2.  **Identify Core & Related Tables:** Find the primary tables containing the requested information and any other tables required for JOIN operations to connect the data.\n",
        "3.  **Extract Exact Schema:** For every table you identify as relevant, copy its full, original `CREATE TABLE ...;` statement.\n",
        "4.  **Output MUST be Clean:**\n",
        "    - Your entire output must ONLY be the sequence of `CREATE TABLE` statements.\n",
        "    - DO NOT include any explanations, reasoning, introductions, or titles.\n",
        "    - DO NOT wrap the output in markdown blocks like ```sql.\n",
        "\n",
        "### Example:\n",
        "If the relevant tables are 'employees' and 'departments', your output should be:\n",
        "CREATE TABLE employees (...);\n",
        "\n",
        "CREATE TABLE departments (...);\n",
        "\"\"\"),\n",
        "        (\"human\", \"\"\"\n",
        "Full Database Schema:\n",
        "{schema}\n",
        "\n",
        "User Question:\n",
        "{question}\n",
        "\"\"\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "schema_filter_chain = SCHEMA_FILTER_PROMPT | llm\n",
        "\n",
        "def schema_path_extractor_node(state: RouterGraphState) -> dict:\n",
        "    \"\"\"\n",
        "    Acts as a schema filter. It extracts only the relevant CREATE TABLE statements\n",
        "    from the full schema based on the user's question.\n",
        "    \"\"\"\n",
        "    print(\"---(3) FILTERING SCHEMA (Context Reduction)---\")\n",
        "    \n",
        "    inputs = {\n",
        "        \"question\": state[\"question\"],\n",
        "        \"schema\": state['schema']\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        response = schema_filter_chain.invoke(inputs)\n",
        "        extracted_schema_subset = response.content.strip()\n",
        "\n",
        "        if not extracted_schema_subset:\n",
        "            raise ValueError(\"LLM returned an empty schema subset.\")\n",
        "\n",
        "        print(f\"✅ Schema subset extracted successfully.\")\n",
        "        return {\"schema_path\": extracted_schema_subset}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Schema filtering failed: {e}. Using full schema as fallback.\")\n",
        "        return {\"schema_path\": state['schema']}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "091dc790",
      "metadata": {
        "id": "091dc790"
      },
      "source": [
        "#### Node: Generator (5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f374e09",
      "metadata": {
        "id": "9f374e09"
      },
      "source": [
        "**Task:** Generate the SQL query based on the question and schema.\n",
        "\n",
        "* If a schema path is available, include it in the prompt.\n",
        "* Save the output query in the `query` field of the state.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "db3a3b83",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import re\n",
        "\n",
        "QUERY_GENERATOR_PROMPT = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"\"\"\n",
        "You are a master SQL generator. Your ONLY task is to write a single, precise, and correct SQL query to answer the user's question based on the provided schema.\n",
        "\n",
        "### RULES:\n",
        "-   Use ONLY the tables and columns present in the provided schema. Do not invent or hallucinate any elements.\n",
        "-   Your entire response MUST be only the SQL query inside a markdown block.\n",
        "-   Do not include any explanations, comments, or any text outside the markdown block.\n",
        "\n",
        "Output format:\n",
        "```sql\n",
        "[YOUR_SQL_QUERY_HERE]\n",
        "\"\"\"),\n",
        "(\"human\", \"\"\"\n",
        "Database Schema:\n",
        "{schema}\n",
        "\n",
        "User Question:\n",
        "{question}\n",
        "\"\"\")\n",
        "]\n",
        ")\n",
        "query_generator_chain = QUERY_GENERATOR_PROMPT | llm\n",
        "\n",
        "def query_generator_node(state: RouterGraphState) -> dict:\n",
        "    \"\"\"\n",
        "    Generates the final SQL query. It uses the filtered schema_path if available,\n",
        "    otherwise it falls back to the full schema. It then sanitizes the output.\n",
        "    \"\"\"\n",
        "    print(\"---(4) GENERATING FINAL SQL QUERY---\")\n",
        "    \n",
        "    effective_schema = state.get(\"schema_path\") or state[\"schema\"]\n",
        "    \n",
        "    print(f\"Using schema for generation (length: {len(effective_schema)} chars)\")\n",
        "    \n",
        "    inputs = {\n",
        "        \"question\": state[\"question\"],\n",
        "        \"schema\": effective_schema\n",
        "    }\n",
        "    \n",
        "    result = query_generator_chain.invoke(inputs)\n",
        "    raw_output = result.content.strip()\n",
        "    \n",
        "    sql_match = re.search(r\"```sql\\s*(.*?)\\s*```\", raw_output, re.DOTALL | re.IGNORECASE)\n",
        "    \n",
        "    if sql_match:\n",
        "        sql_query = sql_match.group(1).strip()\n",
        "    else:\n",
        "        sql_query = raw_output\n",
        "        print(\"⚠️ Could not find a ```sql block. Using raw output as query.\")\n",
        "\n",
        "    print(f\"✅ Final SQL Query Generated:\\n---\\n{sql_query}\\n---\")\n",
        "    return {\"query\": sql_query}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b20d96c",
      "metadata": {
        "id": "6b20d96c"
      },
      "source": [
        "#### Build Graph (5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0416b89b",
      "metadata": {
        "id": "0416b89b"
      },
      "source": [
        "**Task:** Assemble the full routing graph using the nodes and edges you created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "3f58c86e",
      "metadata": {
        "id": "3f58c86e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---(5) BUILDING THE FINAL GRAPH---\n",
            "✅ Graph compiled successfully! It's ready to run.\n"
          ]
        }
      ],
      "source": [
        "from langgraph.graph import StateGraph\n",
        "\n",
        "print(\"---(5) BUILDING THE FINAL GRAPH---\")\n",
        "\n",
        "router_graph_builder = StateGraph(RouterGraphState)\n",
        "\n",
        "router_graph_builder.add_node(\"analyser\", analyser_node)\n",
        "router_graph_builder.add_node(\"schema_path_extractor\", schema_path_extractor_node)\n",
        "router_graph_builder.add_node(\"query_generator\", query_generator_node)\n",
        "\n",
        "router_graph_builder.set_entry_point(\"analyser\")\n",
        "\n",
        "router_graph_builder.add_conditional_edges(\n",
        "    \"analyser\",\n",
        "    is_schema_extraction_needed,\n",
        "    {\n",
        "        \"schema_path_extractor\": \"schema_path_extractor\",\n",
        "        \"query_generator\": \"query_generator\",\n",
        "    }\n",
        ")\n",
        "\n",
        "router_graph_builder.add_edge(\"schema_path_extractor\", \"query_generator\")\n",
        "\n",
        "router_graph_builder.set_finish_point(\"query_generator\")\n",
        "\n",
        "\n",
        "router_graph = router_graph_builder.compile()\n",
        "\n",
        "print(\"✅ Graph compiled successfully! It's ready to run.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "204fab8e",
      "metadata": {
        "id": "204fab8e"
      },
      "source": [
        "#### Run and Evaluate (Estimated Run Time 10-15min)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b90f0bc7",
      "metadata": {
        "id": "b90f0bc7"
      },
      "source": [
        "**Task:** Run your compiled routing graph on a dataset. For each question:\n",
        "\n",
        "* Instantiate the `RouterGraphState` with the question and schema.\n",
        "* Run the graph to completion.\n",
        "* Extract and clean the query from the result.\n",
        "\n",
        "Use the `run_method` function to handle iteration and timing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "585c706f",
      "metadata": {
        "id": "585c706f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/18 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---(1) ANALYZING QUESTION---\n",
            "❌ ERROR during analysis: LLM returned a None response without raising an exception.. Defaulting to 'moderate'.\n",
            "---(2) ROUTING DECISION---\n",
            "Difficulty is 'moderate'. Deciding next step...\n",
            "✅ Routing to: schema_path_extractor\n",
            "---(3) FILTERING SCHEMA (Context Reduction)---\n",
            "✅ Schema subset extracted successfully.\n",
            "---(4) GENERATING FINAL SQL QUERY---\n",
            "Using schema for generation (length: 52 chars)\n",
            "✅ Final SQL Query Generated:\n",
            "---\n",
            "SELECT\n",
            "  CAST(SUM(CASE WHEN bond_type = '-' THEN 1 ELSE 0 END) AS REAL) * 100.0 / COUNT(bond_id)\n",
            "FROM bond;\n",
            "---\n",
            "Question: Find the percentage of atoms with single bond. (Evidence: single bond refers to bond_type = '-'; percentage = DIVIDE(SUM(bond_type = '-'), COUNT(bond_id)) as percentage)\n",
            "Schema: atom (atom_id, molecule_id, element)\n",
            "bond (bond_id, molecule_id, bond_type)\n",
            "connected (atom_id, atom_id2, bond_id)\n",
            "molecule (molecule_id, label)\n",
            "\n",
            "Question Difficulty: moderate\n",
            "Schema Path: CREATE TABLE bond (bond_id, molecule_id, bond_type);\n",
            "Generated SQL: SELECT\n",
            "  CAST(SUM(CASE WHEN bond_type = '-' THEN 1 ELSE 0 END) AS REAL) * 100.0 / COUNT(bond_id)\n",
            "FROM bond;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 1/18 [00:38<10:51, 38.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---(1) ANALYZING QUESTION---\n",
            "❌ ERROR during analysis: LLM returned a None response without raising an exception.. Defaulting to 'moderate'.\n",
            "---(2) ROUTING DECISION---\n",
            "Difficulty is 'moderate'. Deciding next step...\n",
            "✅ Routing to: schema_path_extractor\n",
            "---(3) FILTERING SCHEMA (Context Reduction)---\n",
            "✅ Schema subset extracted successfully.\n",
            "---(4) GENERATING FINAL SQL QUERY---\n",
            "Using schema for generation (length: 149 chars)\n",
            "✅ Final SQL Query Generated:\n",
            "---\n",
            "SELECT\n",
            "  T1.atom_id,\n",
            "  T1.atom_id2\n",
            "FROM connected AS T1\n",
            "INNER JOIN bond AS T2\n",
            "  ON T1.bond_id = T2.bond_id\n",
            "INNER JOIN molecule AS T3\n",
            "  ON T2.molecule_id = T3.molecule_id\n",
            "WHERE\n",
            "  T3.label = '-';\n",
            "---\n",
            "Question: Indicate which atoms are connected in non-carcinogenic type molecules. (Evidence: label = '-' means molecules are non-carcinogenic)\n",
            "Schema: atom (atom_id, molecule_id, element)\n",
            "bond (bond_id, molecule_id, bond_type)\n",
            "connected (atom_id, atom_id2, bond_id)\n",
            "molecule (molecule_id, label)\n",
            "\n",
            "Question Difficulty: moderate\n",
            "Schema Path: CREATE TABLE molecule (molecule_id, label);\n",
            "CREATE TABLE bond (bond_id, molecule_id, bond_type);\n",
            "CREATE TABLE connected (atom_id, atom_id2, bond_id);\n",
            "Generated SQL: SELECT\n",
            "  T1.atom_id,\n",
            "  T1.atom_id2\n",
            "FROM connected AS T1\n",
            "INNER JOIN bond AS T2\n",
            "  ON T1.bond_id = T2.bond_id\n",
            "INNER JOIN molecule AS T3\n",
            "  ON T2.molecule_id = T3.molecule_id\n",
            "WHERE\n",
            "  T3.label = '-';\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 2/18 [01:19<10:36, 39.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---(1) ANALYZING QUESTION---\n",
            "❌ ERROR during analysis: LLM returned a None response without raising an exception.. Defaulting to 'moderate'.\n",
            "---(2) ROUTING DECISION---\n",
            "Difficulty is 'moderate'. Deciding next step...\n",
            "✅ Routing to: schema_path_extractor\n",
            "---(3) FILTERING SCHEMA (Context Reduction)---\n",
            "✅ Schema subset extracted successfully.\n",
            "---(4) GENERATING FINAL SQL QUERY---\n",
            "Using schema for generation (length: 158 chars)\n",
            "⚠️ Could not find a ```sql block. Using raw output as query.\n",
            "✅ Final SQL Query Generated:\n",
            "---\n",
            "\n",
            "---\n",
            "Question: What is the average number of bonds the atoms with the element iodine have? (Evidence: atoms with the element iodine refers to element = 'i'; average = DIVIDE(COUND(bond_id), COUNT(atom_id)) where element = 'i')\n",
            "Schema: atom (atom_id, molecule_id, element)\n",
            "bond (bond_id, molecule_id, bond_type)\n",
            "connected (atom_id, atom_id2, bond_id)\n",
            "molecule (molecule_id, label)\n",
            "\n",
            "Question Difficulty: moderate\n",
            "Schema Path: CREATE TABLE atom (atom_id, molecule_id, element);\n",
            "\n",
            "CREATE TABLE bond (bond_id, molecule_id, bond_type);\n",
            "\n",
            "CREATE TABLE connected (atom_id, atom_id2, bond_id);\n",
            "Generated SQL: \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 3/18 [01:56<09:43, 38.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---(1) ANALYZING QUESTION---\n",
            "❌ ERROR during analysis: LLM returned a None response without raising an exception.. Defaulting to 'moderate'.\n",
            "---(2) ROUTING DECISION---\n",
            "Difficulty is 'moderate'. Deciding next step...\n",
            "✅ Routing to: schema_path_extractor\n",
            "---(3) FILTERING SCHEMA (Context Reduction)---\n",
            "✅ Schema subset extracted successfully.\n",
            "---(4) GENERATING FINAL SQL QUERY---\n",
            "Using schema for generation (length: 147 chars)\n",
            "✅ Final SQL Query Generated:\n",
            "---\n",
            "SELECT T1.molecule_id\n",
            "FROM molecule AS T1\n",
            "INNER JOIN atom AS T2\n",
            "  ON T1.molecule_id = T2.molecule_id\n",
            "INNER JOIN bond AS T3\n",
            "  ON T1.molecule_id = T3.molecule_id\n",
            "WHERE\n",
            "  T2.element = 'c' AND T3.bond_type = '#' AND T1.label = '-'\n",
            "LIMIT 2;\n",
            "---\n",
            "Question: List down two molecule id of triple bond non carcinogenic molecules with element carbon. (Evidence: carbon refers to element = 'c'; triple bond refers to bond_type = '#'; label = '-' means molecules are non-carcinogenic)\n",
            "Schema: atom (atom_id, molecule_id, element)\n",
            "bond (bond_id, molecule_id, bond_type)\n",
            "connected (atom_id, atom_id2, bond_id)\n",
            "molecule (molecule_id, label)\n",
            "\n",
            "Question Difficulty: moderate\n",
            "Schema Path: CREATE TABLE atom (atom_id, molecule_id, element);\n",
            "CREATE TABLE bond (bond_id, molecule_id, bond_type);\n",
            "CREATE TABLE molecule (molecule_id, label);\n",
            "Generated SQL: SELECT T1.molecule_id\n",
            "FROM molecule AS T1\n",
            "INNER JOIN atom AS T2\n",
            "  ON T1.molecule_id = T2.molecule_id\n",
            "INNER JOIN bond AS T3\n",
            "  ON T1.molecule_id = T3.molecule_id\n",
            "WHERE\n",
            "  T2.element = 'c' AND T3.bond_type = '#' AND T1.label = '-'\n",
            "LIMIT 2;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 4/18 [02:33<08:52, 38.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---(1) ANALYZING QUESTION---\n",
            "❌ ERROR during analysis: LLM returned a None response without raising an exception.. Defaulting to 'moderate'.\n",
            "---(2) ROUTING DECISION---\n",
            "Difficulty is 'moderate'. Deciding next step...\n",
            "✅ Routing to: schema_path_extractor\n",
            "---(3) FILTERING SCHEMA (Context Reduction)---\n",
            "✅ Schema subset extracted successfully.\n",
            "---(4) GENERATING FINAL SQL QUERY---\n",
            "Using schema for generation (length: 94 chars)\n",
            "✅ Final SQL Query Generated:\n",
            "---\n",
            "SELECT T1.element, T2.label FROM atom AS T1 JOIN molecule AS T2 ON T1.molecule_id = T2.molecule_id WHERE T1.molecule_id = 'TR060';\n",
            "---\n",
            "Question: What are the elements of the toxicology and label of molecule TR060? (Evidence: TR060 is the molecule id; label = '+' mean molecules are carcinogenic; label = '-' means molecules are non-carcinogenic; element = 'cl' means Chlorine; element = 'c' means Carbon; element = 'h' means Hydrogen; element = 'o' means Oxygen, element = 's' means Sulfur; element = 'n' means Nitrogen, element = 'p' means Phosphorus, element = 'na' means Sodium, element = 'br' means Bromine, element = 'f' means Fluorine; element = 'i' means Iodine; element = 'sn' means Tin; element = 'pb' means Lead; element = 'te' means Tellurium; element = 'ca' means Calcium)\n",
            "Schema: atom (atom_id, molecule_id, element)\n",
            "bond (bond_id, molecule_id, bond_type)\n",
            "connected (atom_id, atom_id2, bond_id)\n",
            "molecule (molecule_id, label)\n",
            "\n",
            "Question Difficulty: moderate\n",
            "Schema Path: CREATE TABLE atom (atom_id, molecule_id, element);\n",
            "CREATE TABLE molecule (molecule_id, label);\n",
            "Generated SQL: SELECT T1.element, T2.label FROM atom AS T1 JOIN molecule AS T2 ON T1.molecule_id = T2.molecule_id WHERE T1.molecule_id = 'TR060';\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 5/18 [03:09<08:04, 37.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---(1) ANALYZING QUESTION---\n",
            "❌ ERROR during analysis: LLM returned a None response without raising an exception.. Defaulting to 'moderate'.\n",
            "---(2) ROUTING DECISION---\n",
            "Difficulty is 'moderate'. Deciding next step...\n",
            "✅ Routing to: schema_path_extractor\n",
            "---(3) FILTERING SCHEMA (Context Reduction)---\n",
            "✅ Schema subset extracted successfully.\n",
            "---(4) GENERATING FINAL SQL QUERY---\n",
            "Using schema for generation (length: 158 chars)\n",
            "✅ Final SQL Query Generated:\n",
            "---\n",
            "SELECT DISTINCT T3.element\n",
            "FROM bond AS T1\n",
            "INNER JOIN connected AS T2\n",
            "  ON T1.bond_id = T2.bond_id\n",
            "INNER JOIN atom AS T3\n",
            "  ON T2.atom_id = T3.atom_id\n",
            "WHERE\n",
            "  T1.bond_id = 'TR001_10_11'\n",
            "UNION\n",
            "SELECT DISTINCT T3.element\n",
            "FROM bond AS T1\n",
            "INNER JOIN connected AS T2\n",
            "  ON T1.bond_id = T2.bond_id\n",
            "INNER JOIN atom AS T3\n",
            "  ON T2.atom_id2 = T3.atom_id\n",
            "WHERE\n",
            "  T1.bond_id = 'TR001_10_11';\n",
            "---\n",
            "Question: What are the elements for bond id TR001_10_11? (Evidence: element = 'cl' means Chlorine; element = 'c' means Carbon; element = 'h' means Hydrogen; element = 'o' means Oxygen, element = 's' means Sulfur; element = 'n' means Nitrogen, element = 'p' means Phosphorus, element = 'na' means Sodium, element = 'br' means Bromine, element = 'f' means Fluorine; element = 'i' means Iodine; element = 'sn' means Tin; element = 'pb' means Lead; element = 'te' means Tellurium; element = 'ca' means Calcium)\n",
            "Schema: atom (atom_id, molecule_id, element)\n",
            "bond (bond_id, molecule_id, bond_type)\n",
            "connected (atom_id, atom_id2, bond_id)\n",
            "molecule (molecule_id, label)\n",
            "\n",
            "Question Difficulty: moderate\n",
            "Schema Path: CREATE TABLE atom (atom_id, molecule_id, element);\n",
            "\n",
            "CREATE TABLE bond (bond_id, molecule_id, bond_type);\n",
            "\n",
            "CREATE TABLE connected (atom_id, atom_id2, bond_id);\n",
            "Generated SQL: SELECT DISTINCT T3.element\n",
            "FROM bond AS T1\n",
            "INNER JOIN connected AS T2\n",
            "  ON T1.bond_id = T2.bond_id\n",
            "INNER JOIN atom AS T3\n",
            "  ON T2.atom_id = T3.atom_id\n",
            "WHERE\n",
            "  T1.bond_id = 'TR001_10_11'\n",
            "UNION\n",
            "SELECT DISTINCT T3.element\n",
            "FROM bond AS T1\n",
            "INNER JOIN connected AS T2\n",
            "  ON T1.bond_id = T2.bond_id\n",
            "INNER JOIN atom AS T3\n",
            "  ON T2.atom_id2 = T3.atom_id\n",
            "WHERE\n",
            "  T1.bond_id = 'TR001_10_11';\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 6/18 [03:46<07:26, 37.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---(1) ANALYZING QUESTION---\n",
            "❌ ERROR during analysis: LLM returned a None response without raising an exception.. Defaulting to 'moderate'.\n",
            "---(2) ROUTING DECISION---\n",
            "Difficulty is 'moderate'. Deciding next step...\n",
            "✅ Routing to: schema_path_extractor\n",
            "---(3) FILTERING SCHEMA (Context Reduction)---\n",
            "✅ Schema subset extracted successfully.\n",
            "---(4) GENERATING FINAL SQL QUERY---\n",
            "Using schema for generation (length: 368 chars)\n",
            "✅ Final SQL Query Generated:\n",
            "---\n",
            "SELECT\n",
            "  COUNT(T1.id)\n",
            "FROM superhero AS T1\n",
            "INNER JOIN publisher AS T2\n",
            "  ON T1.publisher_id = T2.id\n",
            "WHERE\n",
            "  T2.publisher_name = 'Dark Horse Comics';\n",
            "---\n",
            "Question: How many superheroes were published by Dark Horse Comics? (Evidence: published by Dark Horse Comics refers to publisher_name = 'Dark Horse Comics';)\n",
            "Schema: alignment (id, alignment)\n",
            "attribute (id, attribute_name)\n",
            "colour (id, colour)\n",
            "gender (id, gender)\n",
            "publisher (id, publisher_name)\n",
            "race (id, race)\n",
            "superhero (id, superhero_name, full_name, gender_id, eye_colour_id, hair_colour_id, skin_colour_id, race_id, publisher_id, alignment_id, height_cm, weight_kg)\n",
            "hero_attribute (hero_id, attribute_id, attribute_value)\n",
            "superpower (id, power_name)\n",
            "hero_power (hero_id, power_id)\n",
            "\n",
            "Question Difficulty: moderate\n",
            "Schema Path: CREATE TABLE publisher (id INTEGER PRIMARY KEY, publisher_name VARCHAR(255));\n",
            "CREATE TABLE superhero (id INTEGER PRIMARY KEY, superhero_name VARCHAR(255), full_name VARCHAR(255), gender_id INTEGER, eye_colour_id INTEGER, hair_colour_id INTEGER, skin_colour_id INTEGER, race_id INTEGER, publisher_id INTEGER, alignment_id INTEGER, height_cm INTEGER, weight_kg INTEGER);\n",
            "Generated SQL: SELECT\n",
            "  COUNT(T1.id)\n",
            "FROM superhero AS T1\n",
            "INNER JOIN publisher AS T2\n",
            "  ON T1.publisher_id = T2.id\n",
            "WHERE\n",
            "  T2.publisher_name = 'Dark Horse Comics';\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▉      | 7/18 [04:23<06:46, 36.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---(1) ANALYZING QUESTION---\n",
            "❌ ERROR during analysis: LLM returned a None response without raising an exception.. Defaulting to 'moderate'.\n",
            "---(2) ROUTING DECISION---\n",
            "Difficulty is 'moderate'. Deciding next step...\n",
            "✅ Routing to: schema_path_extractor\n",
            "---(3) FILTERING SCHEMA (Context Reduction)---\n",
            "✅ Schema subset extracted successfully.\n",
            "---(4) GENERATING FINAL SQL QUERY---\n",
            "Using schema for generation (length: 390 chars)\n",
            "✅ Final SQL Query Generated:\n",
            "---\n",
            "SELECT T2.race, T3.alignment FROM superhero AS T1 INNER JOIN race AS T2 ON T1.race_id = T2.id INNER JOIN alignment AS T3 ON T1.alignment_id = T3.id WHERE T1.superhero_name = 'Cameron Hicks';\n",
            "---\n",
            "Question: What are the race and alignment of Cameron Hicks? (Evidence: Cameron Hicks refers to superhero_name = 'Cameron Hicks';)\n",
            "Schema: alignment (id, alignment)\n",
            "attribute (id, attribute_name)\n",
            "colour (id, colour)\n",
            "gender (id, gender)\n",
            "publisher (id, publisher_name)\n",
            "race (id, race)\n",
            "superhero (id, superhero_name, full_name, gender_id, eye_colour_id, hair_colour_id, skin_colour_id, race_id, publisher_id, alignment_id, height_cm, weight_kg)\n",
            "hero_attribute (hero_id, attribute_id, attribute_value)\n",
            "superpower (id, power_name)\n",
            "hero_power (hero_id, power_id)\n",
            "\n",
            "Question Difficulty: moderate\n",
            "Schema Path: CREATE TABLE alignment (id INTEGER, alignment VARCHAR(255));\n",
            "CREATE TABLE race (id INTEGER, race VARCHAR(255));\n",
            "CREATE TABLE superhero (id INTEGER, superhero_name VARCHAR(255), full_name VARCHAR(255), gender_id INTEGER, eye_colour_id INTEGER, hair_colour_id INTEGER, skin_colour_id INTEGER, race_id INTEGER, publisher_id INTEGER, alignment_id INTEGER, height_cm INTEGER, weight_kg INTEGER);\n",
            "Generated SQL: SELECT T2.race, T3.alignment FROM superhero AS T1 INNER JOIN race AS T2 ON T1.race_id = T2.id INNER JOIN alignment AS T3 ON T1.alignment_id = T3.id WHERE T1.superhero_name = 'Cameron Hicks';\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 8/18 [05:00<06:09, 36.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---(1) ANALYZING QUESTION---\n",
            "✅ Analysis successful.\n",
            "---(2) ROUTING DECISION---\n",
            "Difficulty is 'simple'. Deciding next step...\n",
            "✅ Routing to: query_generator\n",
            "---(4) GENERATING FINAL SQL QUERY---\n",
            "Using schema for generation (length: 418 chars)\n",
            "✅ Final SQL Query Generated:\n",
            "---\n",
            "SELECT superhero_name\n",
            "FROM superhero\n",
            "WHERE height_cm BETWEEN 170 AND 190 AND eye_colour_id = 1;\n",
            "---\n",
            "Question: Among the superheroes with height from 170 to 190, list the names of the superheroes with no eye color. (Evidence: height from 170 to 190 refers to height_cm BETWEEN 170 AND 190; no eye color refers to eye_colour_id = 1)\n",
            "Schema: alignment (id, alignment)\n",
            "attribute (id, attribute_name)\n",
            "colour (id, colour)\n",
            "gender (id, gender)\n",
            "publisher (id, publisher_name)\n",
            "race (id, race)\n",
            "superhero (id, superhero_name, full_name, gender_id, eye_colour_id, hair_colour_id, skin_colour_id, race_id, publisher_id, alignment_id, height_cm, weight_kg)\n",
            "hero_attribute (hero_id, attribute_id, attribute_value)\n",
            "superpower (id, power_name)\n",
            "hero_power (hero_id, power_id)\n",
            "\n",
            "Question Difficulty: simple\n",
            "Generated SQL: SELECT superhero_name\n",
            "FROM superhero\n",
            "WHERE height_cm BETWEEN 170 AND 190 AND eye_colour_id = 1;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 9/18 [05:33<05:21, 35.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---(1) ANALYZING QUESTION---\n",
            "❌ ERROR during analysis: LLM returned a None response without raising an exception.. Defaulting to 'moderate'.\n",
            "---(2) ROUTING DECISION---\n",
            "Difficulty is 'moderate'. Deciding next step...\n",
            "✅ Routing to: schema_path_extractor\n",
            "---(3) FILTERING SCHEMA (Context Reduction)---\n",
            "✅ Schema subset extracted successfully.\n",
            "---(4) GENERATING FINAL SQL QUERY---\n",
            "Using schema for generation (length: 460 chars)\n",
            "✅ Final SQL Query Generated:\n",
            "---\n",
            "SELECT DISTINCT\n",
            "  T3.power_name\n",
            "FROM gender AS T1\n",
            "INNER JOIN superhero AS T2\n",
            "  ON T1.id = T2.gender_id\n",
            "INNER JOIN hero_power AS T4\n",
            "  ON T2.id = T4.hero_id\n",
            "INNER JOIN superpower AS T3\n",
            "  ON T4.power_id = T3.id\n",
            "WHERE\n",
            "  T1.gender = 'Male'\n",
            "LIMIT 5;\n",
            "---\n",
            "Question: List down at least five superpowers of male superheroes. (Evidence: male refers to gender = 'Male'; superpowers refers to power_name;)\n",
            "Schema: alignment (id, alignment)\n",
            "attribute (id, attribute_name)\n",
            "colour (id, colour)\n",
            "gender (id, gender)\n",
            "publisher (id, publisher_name)\n",
            "race (id, race)\n",
            "superhero (id, superhero_name, full_name, gender_id, eye_colour_id, hair_colour_id, skin_colour_id, race_id, publisher_id, alignment_id, height_cm, weight_kg)\n",
            "hero_attribute (hero_id, attribute_id, attribute_value)\n",
            "superpower (id, power_name)\n",
            "hero_power (hero_id, power_id)\n",
            "\n",
            "Question Difficulty: moderate\n",
            "Schema Path: CREATE TABLE gender (id INTEGER, gender VARCHAR(255));\n",
            "\n",
            "CREATE TABLE superhero (id INTEGER, superhero_name VARCHAR(255), full_name VARCHAR(255), gender_id INTEGER, eye_colour_id INTEGER, hair_colour_id INTEGER, skin_colour_id INTEGER, race_id INTEGER, publisher_id INTEGER, alignment_id INTEGER, height_cm INTEGER, weight_kg INTEGER);\n",
            "\n",
            "CREATE TABLE superpower (id INTEGER, power_name VARCHAR(255));\n",
            "\n",
            "CREATE TABLE hero_power (hero_id INTEGER, power_id INTEGER);\n",
            "Generated SQL: SELECT DISTINCT\n",
            "  T3.power_name\n",
            "FROM gender AS T1\n",
            "INNER JOIN superhero AS T2\n",
            "  ON T1.id = T2.gender_id\n",
            "INNER JOIN hero_power AS T4\n",
            "  ON T2.id = T4.hero_id\n",
            "INNER JOIN superpower AS T3\n",
            "  ON T4.power_id = T3.id\n",
            "WHERE\n",
            "  T1.gender = 'Male'\n",
            "LIMIT 5;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 10/18 [06:10<04:48, 36.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---(1) ANALYZING QUESTION---\n",
            "❌ ERROR during analysis: LLM returned a None response without raising an exception.. Defaulting to 'moderate'.\n",
            "---(2) ROUTING DECISION---\n",
            "Difficulty is 'moderate'. Deciding next step...\n",
            "✅ Routing to: schema_path_extractor\n",
            "---(3) FILTERING SCHEMA (Context Reduction)---\n",
            "✅ Schema subset extracted successfully.\n",
            "---(4) GENERATING FINAL SQL QUERY---\n",
            "Using schema for generation (length: 405 chars)\n",
            "⚠️ Could not find a ```sql block. Using raw output as query.\n",
            "✅ Final SQL Query Generated:\n",
            "---\n",
            "\n",
            "---\n",
            "Question: What is the percentage of superheroes who act in their own self-interest or make decisions based on their own moral code? Indicate how many of the said superheroes were published by Marvel Comics. (Evidence: published by Marvel Comics refers to publisher_name = 'Marvel Comics'; superheroes who act in their own self-interest or make decisions based on their own moral code refers to alignment = 'Bad'; calculation = MULTIPLY(DIVIDE(SUM(alignment = 'Bad); count(id)), 100))\n",
            "Schema: alignment (id, alignment)\n",
            "attribute (id, attribute_name)\n",
            "colour (id, colour)\n",
            "gender (id, gender)\n",
            "publisher (id, publisher_name)\n",
            "race (id, race)\n",
            "superhero (id, superhero_name, full_name, gender_id, eye_colour_id, hair_colour_id, skin_colour_id, race_id, publisher_id, alignment_id, height_cm, weight_kg)\n",
            "hero_attribute (hero_id, attribute_id, attribute_value)\n",
            "superpower (id, power_name)\n",
            "hero_power (hero_id, power_id)\n",
            "\n",
            "Question Difficulty: moderate\n",
            "Schema Path: CREATE TABLE alignment (id INTEGER, alignment VARCHAR(255));\n",
            "CREATE TABLE publisher (id INTEGER, publisher_name VARCHAR(255));\n",
            "CREATE TABLE superhero (id INTEGER, superhero_name VARCHAR(255), full_name VARCHAR(255), gender_id INTEGER, eye_colour_id INTEGER, hair_colour_id INTEGER, skin_colour_id INTEGER, race_id INTEGER, publisher_id INTEGER, alignment_id INTEGER, height_cm INTEGER, weight_kg INTEGER);\n",
            "Generated SQL: \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████    | 11/18 [06:47<04:16, 36.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---(1) ANALYZING QUESTION---\n",
            "✅ Analysis successful.\n",
            "---(2) ROUTING DECISION---\n",
            "Difficulty is 'moderate'. Deciding next step...\n",
            "✅ Routing to: schema_path_extractor\n",
            "---(3) FILTERING SCHEMA (Context Reduction)---\n",
            "✅ Schema subset extracted successfully.\n",
            "---(4) GENERATING FINAL SQL QUERY---\n",
            "Using schema for generation (length: 719 chars)\n",
            "⚠️ Could not find a ```sql block. Using raw output as query.\n",
            "✅ Final SQL Query Generated:\n",
            "---\n",
            "\n",
            "---\n",
            "Question: Which publisher created more superheroes: DC or Marvel Comics? Find the difference in the number of superheroes. (Evidence: DC refers to publisher_name = 'DC Comics'; Marvel Comics refers to publisher_name = 'Marvel Comics'; if SUM(publisher_name = 'DC Comics') > SUM(publisher_name = 'Marvel Comics'), it means DC Comics published more superheroes than Marvel Comics; if SUM(publisher_name = 'Marvel Comics') > SUM(publisher_name = 'Marvel Comics'), it means Marvel Comics published more heroes than DC Comics; difference = SUBTRACT(SUM(publisher_name = 'DC Comics'), SUM(publisher_name = 'Marvel Comics'));)\n",
            "Schema: alignment (id, alignment)\n",
            "attribute (id, attribute_name)\n",
            "colour (id, colour)\n",
            "gender (id, gender)\n",
            "publisher (id, publisher_name)\n",
            "race (id, race)\n",
            "superhero (id, superhero_name, full_name, gender_id, eye_colour_id, hair_colour_id, skin_colour_id, race_id, publisher_id, alignment_id, height_cm, weight_kg)\n",
            "hero_attribute (hero_id, attribute_id, attribute_value)\n",
            "superpower (id, power_name)\n",
            "hero_power (hero_id, power_id)\n",
            "\n",
            "Question Difficulty: moderate\n",
            "Schema Path: CREATE TABLE publisher (id INTEGER PRIMARY KEY, publisher_name VARCHAR(255));\n",
            "CREATE TABLE superhero (id INTEGER PRIMARY KEY, superhero_name VARCHAR(255), full_name VARCHAR(255), gender_id INTEGER, eye_colour_id INTEGER, hair_colour_id INTEGER, skin_colour_id INTEGER, race_id INTEGER, publisher_id INTEGER, alignment_id INTEGER, height_cm INTEGER, weight_kg INTEGER, FOREIGN KEY (gender_id) REFERENCES gender(id), FOREIGN KEY (eye_colour_id) REFERENCES colour(id), FOREIGN KEY (hair_colour_id) REFERENCES colour(id), FOREIGN KEY (skin_colour_id) REFERENCES colour(id), FOREIGN KEY (race_id) REFERENCES race(id), FOREIGN KEY (publisher_id) REFERENCES publisher(id), FOREIGN KEY (alignment_id) REFERENCES alignment(id));\n",
            "Generated SQL: \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 12/18 [07:25<03:42, 37.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---(1) ANALYZING QUESTION---\n",
            "❌ ERROR during analysis: LLM returned a None response without raising an exception.. Defaulting to 'moderate'.\n",
            "---(2) ROUTING DECISION---\n",
            "Difficulty is 'moderate'. Deciding next step...\n",
            "✅ Routing to: schema_path_extractor\n",
            "---(3) FILTERING SCHEMA (Context Reduction)---\n",
            "✅ Schema subset extracted successfully.\n",
            "---(4) GENERATING FINAL SQL QUERY---\n",
            "Using schema for generation (length: 312 chars)\n",
            "✅ Final SQL Query Generated:\n",
            "---\n",
            "SELECT\n",
            "  T2.first_name,\n",
            "  T2.last_name\n",
            "FROM income AS T1\n",
            "INNER JOIN member AS T2\n",
            "  ON T1.link_to_member = T2.member_id\n",
            "WHERE\n",
            "  T1.source = 'Dues'\n",
            "ORDER BY\n",
            "  T1.date_received\n",
            "LIMIT 1;\n",
            "---\n",
            "Question: Who was the first one paid his/her dues? Tell the full name. (Evidence: full name refers to first_name, last_name; first paid dues refers to MIN(received_date) where source = 'Dues')\n",
            "Schema: event (event_id, event_name, event_date, type, notes, location, status)\n",
            "major (major_id, major_name, department, college)\n",
            "zip_code (zip_code, type, city, county, state, short_state)\n",
            "attendance (link_to_event, link_to_member)\n",
            "budget (budget_id, category, spent, remaining, amount, event_status, link_to_event)\n",
            "expense (expense_id, expense_description, expense_date, cost, approved, link_to_member, link_to_budget)\n",
            "income (income_id, date_received, amount, source, notes, link_to_member)\n",
            "member (member_id, first_name, last_name, email, position, t_shirt_size, phone, zip, link_to_major)\n",
            "\n",
            "Question Difficulty: moderate\n",
            "Schema Path: CREATE TABLE income (income_id INTEGER PRIMARY KEY, date_received DATE, amount REAL, source TEXT, notes TEXT, link_to_member INTEGER);\n",
            "\n",
            "CREATE TABLE member (member_id INTEGER PRIMARY KEY, first_name TEXT, last_name TEXT, email TEXT, position TEXT, t_shirt_size TEXT, phone TEXT, zip TEXT, link_to_major INTEGER);\n",
            "Generated SQL: SELECT\n",
            "  T2.first_name,\n",
            "  T2.last_name\n",
            "FROM income AS T1\n",
            "INNER JOIN member AS T2\n",
            "  ON T1.link_to_member = T2.member_id\n",
            "WHERE\n",
            "  T1.source = 'Dues'\n",
            "ORDER BY\n",
            "  T1.date_received\n",
            "LIMIT 1;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 13/18 [08:02<03:04, 36.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---(1) ANALYZING QUESTION---\n",
            "❌ ERROR during analysis: LLM returned a None response without raising an exception.. Defaulting to 'moderate'.\n",
            "---(2) ROUTING DECISION---\n",
            "Difficulty is 'moderate'. Deciding next step...\n",
            "✅ Routing to: schema_path_extractor\n",
            "---(3) FILTERING SCHEMA (Context Reduction)---\n",
            "✅ Schema subset extracted successfully.\n",
            "---(4) GENERATING FINAL SQL QUERY---\n",
            "Using schema for generation (length: 86 chars)\n",
            "✅ Final SQL Query Generated:\n",
            "---\n",
            "SELECT count(*) FROM income WHERE amount = 50;\n",
            "---\n",
            "Question: How many income are received with an amount of 50? (Evidence: amount of 50 refers to amount = 50)\n",
            "Schema: event (event_id, event_name, event_date, type, notes, location, status)\n",
            "major (major_id, major_name, department, college)\n",
            "zip_code (zip_code, type, city, county, state, short_state)\n",
            "attendance (link_to_event, link_to_member)\n",
            "budget (budget_id, category, spent, remaining, amount, event_status, link_to_event)\n",
            "expense (expense_id, expense_description, expense_date, cost, approved, link_to_member, link_to_budget)\n",
            "income (income_id, date_received, amount, source, notes, link_to_member)\n",
            "member (member_id, first_name, last_name, email, position, t_shirt_size, phone, zip, link_to_major)\n",
            "\n",
            "Question Difficulty: moderate\n",
            "Schema Path: CREATE TABLE income (income_id, date_received, amount, source, notes, link_to_member);\n",
            "Generated SQL: SELECT count(*) FROM income WHERE amount = 50;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 14/18 [08:37<02:25, 36.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---(1) ANALYZING QUESTION---\n",
            "❌ ERROR during analysis: LLM returned a None response without raising an exception.. Defaulting to 'moderate'.\n",
            "---(2) ROUTING DECISION---\n",
            "Difficulty is 'moderate'. Deciding next step...\n",
            "✅ Routing to: schema_path_extractor\n",
            "---(3) FILTERING SCHEMA (Context Reduction)---\n",
            "✅ Schema subset extracted successfully.\n",
            "---(4) GENERATING FINAL SQL QUERY---\n",
            "Using schema for generation (length: 421 chars)\n",
            "✅ Final SQL Query Generated:\n",
            "---\n",
            "SELECT T1.event_name\n",
            "FROM event AS T1\n",
            "INNER JOIN budget AS T2\n",
            "  ON T1.event_id = T2.link_to_event\n",
            "WHERE\n",
            "  T2.category = 'Advertisement'\n",
            "ORDER BY\n",
            "  T2.spent DESC\n",
            "LIMIT 1;\n",
            "---\n",
            "Question: Name the event with the highest amount spent on advertisement. (Evidence: event refers to event_name; highest amount spent on advertisement refers to MAX(spent) where category = 'Advertisement')\n",
            "Schema: event (event_id, event_name, event_date, type, notes, location, status)\n",
            "major (major_id, major_name, department, college)\n",
            "zip_code (zip_code, type, city, county, state, short_state)\n",
            "attendance (link_to_event, link_to_member)\n",
            "budget (budget_id, category, spent, remaining, amount, event_status, link_to_event)\n",
            "expense (expense_id, expense_description, expense_date, cost, approved, link_to_member, link_to_budget)\n",
            "income (income_id, date_received, amount, source, notes, link_to_member)\n",
            "member (member_id, first_name, last_name, email, position, t_shirt_size, phone, zip, link_to_major)\n",
            "\n",
            "Question Difficulty: moderate\n",
            "Schema Path: CREATE TABLE event (event_id INTEGER PRIMARY KEY, event_name VARCHAR(255), event_date DATE, type VARCHAR(255), notes TEXT, location VARCHAR(255), status VARCHAR(255));\n",
            "\n",
            "CREATE TABLE budget (budget_id INTEGER PRIMARY KEY, category VARCHAR(255), spent DECIMAL(10, 2), remaining DECIMAL(10, 2), amount DECIMAL(10, 2), event_status VARCHAR(255), link_to_event INTEGER, FOREIGN KEY (link_to_event) REFERENCES event(event_id));\n",
            "Generated SQL: SELECT T1.event_name\n",
            "FROM event AS T1\n",
            "INNER JOIN budget AS T2\n",
            "  ON T1.event_id = T2.link_to_event\n",
            "WHERE\n",
            "  T2.category = 'Advertisement'\n",
            "ORDER BY\n",
            "  T2.spent DESC\n",
            "LIMIT 1;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 15/18 [09:13<01:49, 36.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---(1) ANALYZING QUESTION---\n",
            "✅ Analysis successful.\n",
            "---(2) ROUTING DECISION---\n",
            "Difficulty is 'moderate'. Deciding next step...\n",
            "✅ Routing to: schema_path_extractor\n",
            "---(3) FILTERING SCHEMA (Context Reduction)---\n",
            "✅ Schema subset extracted successfully.\n",
            "---(4) GENERATING FINAL SQL QUERY---\n",
            "Using schema for generation (length: 303 chars)\n",
            "✅ Final SQL Query Generated:\n",
            "---\n",
            "SELECT\n",
            "  SUM(CASE WHEN T1.event_name = 'Yearly Kickoff' THEN T2.cost ELSE 0 END) * 100.0 / SUM(T2.cost)\n",
            "FROM event AS T1\n",
            "INNER JOIN expense AS T2\n",
            "  ON T1.event_id = T2.link_to_event;\n",
            "---\n",
            "Question: Based on the total cost for all event, what is the percentage of cost for Yearly Kickoff event? (Evidence: DIVIDE(SUM(cost where event_name = 'Yearly Kickoff'), SUM(cost)) * 100)\n",
            "Schema: event (event_id, event_name, event_date, type, notes, location, status)\n",
            "major (major_id, major_name, department, college)\n",
            "zip_code (zip_code, type, city, county, state, short_state)\n",
            "attendance (link_to_event, link_to_member)\n",
            "budget (budget_id, category, spent, remaining, amount, event_status, link_to_event)\n",
            "expense (expense_id, expense_description, expense_date, cost, approved, link_to_member, link_to_budget)\n",
            "income (income_id, date_received, amount, source, notes, link_to_member)\n",
            "member (member_id, first_name, last_name, email, position, t_shirt_size, phone, zip, link_to_major)\n",
            "\n",
            "Question Difficulty: moderate\n",
            "Schema Path: CREATE TABLE event (event_id, event_name, event_date, type, notes, location, status);\n",
            "\n",
            "CREATE TABLE budget (budget_id, category, spent, remaining, amount, event_status, link_to_event);\n",
            "\n",
            "CREATE TABLE expense (expense_id, expense_description, expense_date, cost, approved, link_to_member, link_to_budget);\n",
            "Generated SQL: SELECT\n",
            "  SUM(CASE WHEN T1.event_name = 'Yearly Kickoff' THEN T2.cost ELSE 0 END) * 100.0 / SUM(T2.cost)\n",
            "FROM event AS T1\n",
            "INNER JOIN expense AS T2\n",
            "  ON T1.event_id = T2.link_to_event;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 89%|████████▉ | 16/18 [09:49<01:12, 36.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---(1) ANALYZING QUESTION---\n",
            "❌ ERROR during analysis: LLM returned a None response without raising an exception.. Defaulting to 'moderate'.\n",
            "---(2) ROUTING DECISION---\n",
            "Difficulty is 'moderate'. Deciding next step...\n",
            "✅ Routing to: schema_path_extractor\n",
            "---(3) FILTERING SCHEMA (Context Reduction)---\n",
            "✅ Schema subset extracted successfully.\n",
            "---(4) GENERATING FINAL SQL QUERY---\n",
            "Using schema for generation (length: 232 chars)\n",
            "✅ Final SQL Query Generated:\n",
            "---\n",
            "SELECT\n",
            "  AVG(T1.cost)\n",
            "FROM expense AS T1\n",
            "INNER JOIN member AS T2\n",
            "  ON T1.link_to_member = T2.member_id\n",
            "WHERE\n",
            "  T2.first_name = 'Elijah' AND T2.last_name = 'Allen' AND (\n",
            "    STRFTIME('%m', T1.expense_date) = '09' OR STRFTIME('%m', T1.expense_date) = '10'\n",
            "  );\n",
            "---\n",
            "Question: Calculate the total average cost that Elijah Allen spent in the events on September and October. (Evidence: events in September and October refers to month(expense_date) = 9 AND MONTH(expense_date) = 10)\n",
            "Schema: event (event_id, event_name, event_date, type, notes, location, status)\n",
            "major (major_id, major_name, department, college)\n",
            "zip_code (zip_code, type, city, county, state, short_state)\n",
            "attendance (link_to_event, link_to_member)\n",
            "budget (budget_id, category, spent, remaining, amount, event_status, link_to_event)\n",
            "expense (expense_id, expense_description, expense_date, cost, approved, link_to_member, link_to_budget)\n",
            "income (income_id, date_received, amount, source, notes, link_to_member)\n",
            "member (member_id, first_name, last_name, email, position, t_shirt_size, phone, zip, link_to_major)\n",
            "\n",
            "Question Difficulty: moderate\n",
            "Schema Path: CREATE TABLE expense (expense_id, expense_description, expense_date, cost, approved, link_to_member, link_to_budget);\n",
            "\n",
            "CREATE TABLE member (member_id, first_name, last_name, email, position, t_shirt_size, phone, zip, link_to_major);\n",
            "Generated SQL: SELECT\n",
            "  AVG(T1.cost)\n",
            "FROM expense AS T1\n",
            "INNER JOIN member AS T2\n",
            "  ON T1.link_to_member = T2.member_id\n",
            "WHERE\n",
            "  T2.first_name = 'Elijah' AND T2.last_name = 'Allen' AND (\n",
            "    STRFTIME('%m', T1.expense_date) = '09' OR STRFTIME('%m', T1.expense_date) = '10'\n",
            "  );\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 17/18 [10:26<00:36, 36.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---(1) ANALYZING QUESTION---\n",
            "❌ ERROR during analysis: LLM returned a None response without raising an exception.. Defaulting to 'moderate'.\n",
            "---(2) ROUTING DECISION---\n",
            "Difficulty is 'moderate'. Deciding next step...\n",
            "✅ Routing to: schema_path_extractor\n",
            "---(3) FILTERING SCHEMA (Context Reduction)---\n",
            "✅ Schema subset extracted successfully.\n",
            "---(4) GENERATING FINAL SQL QUERY---\n",
            "Using schema for generation (length: 303 chars)\n",
            "✅ Final SQL Query Generated:\n",
            "---\n",
            "SELECT DISTINCT\n",
            "  T1.event_name,\n",
            "  T1.event_date\n",
            "FROM event AS T1\n",
            "INNER JOIN budget AS T2\n",
            "  ON T1.event_id = T2.link_to_event\n",
            "INNER JOIN expense AS T3\n",
            "  ON T2.budget_id = T3.link_to_budget\n",
            "WHERE\n",
            "  T3.expense_description = 'Pizza' AND T3.cost > 50 AND T3.cost < 100;\n",
            "---\n",
            "Question: Find the name and date of events with expenses for pizza that were more than fifty dollars but less than a hundred dollars. (Evidence: name of event refers to event_name; date of event refers to event_date; expenses for pizza refers to expense_description = 'Pizza' where cost > 50 and cost < 100)\n",
            "Schema: event (event_id, event_name, event_date, type, notes, location, status)\n",
            "major (major_id, major_name, department, college)\n",
            "zip_code (zip_code, type, city, county, state, short_state)\n",
            "attendance (link_to_event, link_to_member)\n",
            "budget (budget_id, category, spent, remaining, amount, event_status, link_to_event)\n",
            "expense (expense_id, expense_description, expense_date, cost, approved, link_to_member, link_to_budget)\n",
            "income (income_id, date_received, amount, source, notes, link_to_member)\n",
            "member (member_id, first_name, last_name, email, position, t_shirt_size, phone, zip, link_to_major)\n",
            "\n",
            "Question Difficulty: moderate\n",
            "Schema Path: CREATE TABLE event (event_id, event_name, event_date, type, notes, location, status);\n",
            "\n",
            "CREATE TABLE budget (budget_id, category, spent, remaining, amount, event_status, link_to_event);\n",
            "\n",
            "CREATE TABLE expense (expense_id, expense_description, expense_date, cost, approved, link_to_member, link_to_budget);\n",
            "Generated SQL: SELECT DISTINCT\n",
            "  T1.event_name,\n",
            "  T1.event_date\n",
            "FROM event AS T1\n",
            "INNER JOIN budget AS T2\n",
            "  ON T1.event_id = T2.link_to_event\n",
            "INNER JOIN expense AS T3\n",
            "  ON T2.budget_id = T3.link_to_budget\n",
            "WHERE\n",
            "  T3.expense_description = 'Pizza' AND T3.cost > 50 AND T3.cost < 100;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [11:03<00:00, 36.84s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting to compare without knowledge for ex\n",
            "Process finished successfully\n",
            "start calculate\n",
            "                     simple               moderate             challenging          total               \n",
            "count                6                    6                    6                    18                  \n",
            "======================================    ACCURACY    =====================================\n",
            "accuracy             66.67                66.67                83.33                72.22               \n",
            "===========================================================================================\n",
            "Finished evaluation\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from method_run import run_method\n",
        "def run_router_graph(item):\n",
        "    response = router_graph.invoke(\n",
        "        RouterGraphState(\n",
        "            question=item['question'],\n",
        "            schema=item['schema'],\n",
        "            schema_path=None,\n",
        "            question_difficulty=None,\n",
        "            query=None\n",
        "        )\n",
        "    )\n",
        "    result = response[\"query\"]\n",
        "    # First try to extract query from markdown SQL block\n",
        "    match = re.search(r'```sql\\n(.*?)```', result, re.DOTALL)\n",
        "    if match:\n",
        "        query = match.group(1).strip()\n",
        "    else:\n",
        "        # If no markdown block found, try to extract just SQL query\n",
        "        query = result.strip()\n",
        "        # Remove any ```sql or ``` if present without proper formatting\n",
        "        query = re.sub(r'```sql|```', '', query).strip()\n",
        "    print(f\"Question: {item['question']}\")\n",
        "    print(f\"Schema: {item['schema']}\")\n",
        "    print(f\"Question Difficulty: {response['question_difficulty']}\")\n",
        "    if response[\"schema_path\"]:\n",
        "        print(f\"Schema Path: {response['schema_path']}\")\n",
        "    print(f\"Generated SQL: {query}\\n\")\n",
        "    return {**item, 'sql': query}\n",
        "\n",
        "\n",
        "run_method(run_router_graph, SLEEP_TIME=30)\n",
        "\n",
        "#Run on mode=nano if you want to test it on a smaller dataset\n",
        "# run_method(run_router_graph, SLEEP_TIME=15, mode=\"nano\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4666dff4",
      "metadata": {
        "id": "4666dff4"
      },
      "source": [
        "### Agent (ReAct)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bc99580",
      "metadata": {
        "id": "5bc99580"
      },
      "source": [
        "Now you will implement a full ReAct agent that incrementally solves the Text-to-SQL task using tools. The agent can explore tables and columns before finalizing the query."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1df0a65",
      "metadata": {
        "id": "d1df0a65"
      },
      "source": [
        "**You are not allowed to use 'Prebuilt Agent' of LangGraph. You have to build your own graph.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9505b9f8",
      "metadata": {
        "id": "9505b9f8"
      },
      "source": [
        "#### Define Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07b3582a",
      "metadata": {
        "id": "07b3582a"
      },
      "source": [
        "**Task:** Define three tools for the agent to interact with the schema:\n",
        "1. `get_samples_from_table`: Returns the first few rows of a table.\n",
        "2. `get_column_description`: Provides a human-readable description of a specific column.\n",
        "3. `execute`: Executes a SQL query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4ab00e13",
      "metadata": {
        "id": "4ab00e13"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "from db_manager import DBManager\n",
        "db_manager = DBManager()\n",
        "\n",
        "@tool\n",
        "def get_samples_from_table(table_name: str, config: RunnableConfig):\n",
        "  \"\"\"Gets the first few rows (samples) from a specified table.\n",
        "\n",
        "  Args:\n",
        "    table_name: The name of the table from which to fetch samples.\n",
        "\n",
        "  Returns:\n",
        "    The first few rows from the specified table.\n",
        "  \"\"\"\n",
        "  db_name = config[\"configurable\"].get(\"database_name\")\n",
        "  result = db_manager.get_table_head(table_name, db_name=db_name)\n",
        "  return result\n",
        "\n",
        "@tool\n",
        "def get_column_description(table_name: str, column_name: str, config: RunnableConfig):\n",
        "  \"\"\"Provides a description for a specific column within a given table.\n",
        "\n",
        "  Args:\n",
        "    table_name: The name of the table containing the column.\n",
        "    column_name: The name of the column for which to get the description.\n",
        "\n",
        "  Returns:\n",
        "    A string containing the description of the specified column.\n",
        "  \"\"\"\n",
        "  db_name = config[\"configurable\"].get(\"database_name\")\n",
        "  result = db_manager.get_column_description(db_name, table_name, column_name)\n",
        "  return result\n",
        "\n",
        "@tool\n",
        "def execute(query: str, config: RunnableConfig):\n",
        "  \"\"\"Executes a given SQL query against the database.\n",
        "\n",
        "  Args:\n",
        "    query: The SQL query string to be executed.\n",
        "\n",
        "  Returns:\n",
        "    The result of the executed query. This could be a set of rows,\n",
        "    a confirmation message, or an error.\n",
        "  \"\"\"\n",
        "  db_name = config[\"configurable\"].get(\"database_name\")\n",
        "  result = db_manager.query(query, db_name)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66680244",
      "metadata": {
        "id": "66680244"
      },
      "source": [
        "#### Extra Tool (5+5 Bonus Points):"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f80baae9",
      "metadata": {
        "id": "f80baae9"
      },
      "source": [
        "**Task**: Create and integrate a new custom tool into the ReAct agent. To receive credit for this part, your tool must be meaningfully different from the existing three tools and provide practical value in helping the agent generate more accurate or efficient SQL queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7c0308d9",
      "metadata": {
        "id": "7c0308d9"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def find_foreign_key_relations(table_name: str, config: RunnableConfig):\n",
        "  \"\"\"Finds foreign key relationships for a specified table to help with JOINs.\n",
        "\n",
        "  Args:\n",
        "    table_name: The name of the table for which to find foreign key relations.\n",
        "\n",
        "  Returns:\n",
        "    A formatted string describing the foreign key relations.\n",
        "  \"\"\"\n",
        "  db_name = config[\"configurable\"].get(\"database_name\")\n",
        "  relations = db_manager.get_foreign_keys(db_name=db_name, table_name=table_name)\n",
        "\n",
        "  if not relations:\n",
        "    return f\"No foreign key relations found for table '{table_name}'.\"\n",
        "  \n",
        "  output_lines = [\n",
        "      f\"- Column '{relation['from_column']}' points to column '{relation['target_column']}' in table '{relation['target_table']}'.\"\n",
        "      for relation in relations\n",
        "  ]\n",
        "  \n",
        "  return \"\\n\".join(output_lines)\n",
        "\n",
        "@tool\n",
        "def list_all_tables(config: RunnableConfig):\n",
        "  \"\"\"Lists all tables in the current database.\n",
        "\n",
        "  Returns:\n",
        "    A formatted string containing the names of all tables in the database.\n",
        "  \"\"\"\n",
        "  db_name = config[\"configurable\"].get(\"database_name\")\n",
        "  tables = db_manager.get_tables(db_name=db_name) \n",
        "  \n",
        "  if not tables:\n",
        "    return \"No tables found in the database.\"\n",
        "  \n",
        "  return \"Tables in the database:\\n\" + \"\\n\".join(f\"- {table}\" for table in tables)\n",
        "\n",
        "@tool\n",
        "def get_table_schema(table_name: str, config: RunnableConfig):\n",
        "  \"\"\"Retrieves the schema (CREATE TABLE statement) for a specified table.\n",
        "\n",
        "  Args:\n",
        "    table_name: The name of the table whose schema is to be retrieved.\n",
        "\n",
        "  Returns:\n",
        "    The CREATE TABLE statement for the specified table.\n",
        "  \"\"\"\n",
        "  db_name = config[\"configurable\"].get(\"database_name\")\n",
        "  schema = db_manager.get_table_schema(table_name, db_name=db_name)\n",
        "  return schema\n",
        "\n",
        "@tool\n",
        "def get_related_tables(table_name: str, config: RunnableConfig):\n",
        "  \"\"\"Finds tables that are related to the specified table via foreign keys.\n",
        "\n",
        "  Args:\n",
        "    table_name: The name of the table for which to find related tables.\n",
        "\n",
        "  Returns:\n",
        "    A formatted string listing the names of related tables.\n",
        "  \"\"\"\n",
        "  db_name = config[\"configurable\"].get(\"database_name\")\n",
        "  related_tables = db_manager.get_related_tables(db_name=db_name, table_name=table_name)\n",
        "\n",
        "  if not related_tables:\n",
        "    return f\"No related tables found for '{table_name}'.\"\n",
        "  \n",
        "  return \"Related tables:\\n\" + \"\\n\".join(f\"- {table}\" for table in related_tables)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfbe11d0",
      "metadata": {
        "id": "cfbe11d0"
      },
      "source": [
        "#### Create Tool Node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b24a997",
      "metadata": {
        "id": "2b24a997"
      },
      "outputs": [],
      "source": [
        "tools = [get_samples_from_table, get_column_description, execute,\n",
        "         find_foreign_key_relations, list_all_tables, get_table_schema,\n",
        "         get_related_tables]\n",
        "\n",
        "tools_node = ToolNode(tools=tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8348623d",
      "metadata": {
        "id": "8348623d"
      },
      "source": [
        "#### ReAct Agent Prompt (5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08d0f151",
      "metadata": {
        "id": "08d0f151"
      },
      "source": [
        "**Task:** Set up the agent node with planning, tool use, and final SQL generation prompts. For writing efficient prompt you can read this link.\n",
        "https://cookbook.openai.com/examples/gpt4-1_prompting_guide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35c8f0de",
      "metadata": {
        "id": "35c8f0de"
      },
      "outputs": [],
      "source": [
        "REACT_SYS_PROMPT = \"\"\"\n",
        "#YOUR PROMPT HERE\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ee385fd",
      "metadata": {
        "id": "7ee385fd"
      },
      "source": [
        "#### Agent Node (5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0549f4b1",
      "metadata": {
        "id": "0549f4b1"
      },
      "source": [
        "**Task:** Set up the agent node with models that have binded with tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4247575c",
      "metadata": {
        "id": "4247575c"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def agent_node(state: MessagesState) -> MessagesState:\n",
        "    #For rate-limiting purposes, we will sleep for 10 seconds before invoking the LLM\n",
        "    time.sleep(10)\n",
        "    #YOUR CODE HERE\n",
        "    return state"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fe4d541",
      "metadata": {
        "id": "3fe4d541"
      },
      "source": [
        "#### Build Graph (5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39bbf177",
      "metadata": {
        "id": "39bbf177"
      },
      "source": [
        "**Task:** Assemble the ReAct agent graph, connecting the agent node and tool node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d770ec0f",
      "metadata": {
        "id": "d770ec0f"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import tools_condition\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "class ConfigSchema(TypedDict):\n",
        "    database_name: str\n",
        "\n",
        "react_builder = StateGraph(MessagesState, config_schema=ConfigSchema)\n",
        "\n",
        "#YOUR CODE HERE\n",
        "\n",
        "react_graph = react_builder.compile()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c7aee0f",
      "metadata": {
        "id": "7c7aee0f"
      },
      "source": [
        "#### Run and Evaluate (Estimated Run Time 20min)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f4a2020",
      "metadata": {
        "id": "0f4a2020"
      },
      "source": [
        "**Task:** Execute the ReAct agent pipeline on the dataset and collect SQL outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9184c4c",
      "metadata": {
        "id": "a9184c4c"
      },
      "outputs": [],
      "source": [
        "from method_run import run_method\n",
        "import re\n",
        "def run_react_agent_with_config(item):\n",
        "    question = item['question']\n",
        "    schema = item['schema']\n",
        "    user_prompt = f\"Question: {question}\\nSchema: {schema}\"\n",
        "    input_msg = HumanMessage(content=user_prompt)\n",
        "    input_config = {\"configurable\": {\"database_name\": item['db_id']}}\n",
        "    response = react_graph.invoke(MessagesState(messages=[input_msg]), config=input_config)\n",
        "\n",
        "    for msg in response[\"messages\"]:\n",
        "        msg.pretty_print()\n",
        "\n",
        "    # If last AI Message is a list of messages, we need to extract the last one\n",
        "    last_msg = response[\"messages\"][-1].content\n",
        "    if isinstance(last_msg, list):\n",
        "        last_msg = last_msg[-1]\n",
        "\n",
        "    # First try to extract query from markdown SQL block\n",
        "    match = re.search(r'```sql\\n(.*?)```', last_msg, re.DOTALL)\n",
        "    if match:\n",
        "        query = match.group(1).strip()\n",
        "    else:\n",
        "        # If no markdown block found, try to extract just SQL query\n",
        "        query = last_msg.strip()\n",
        "        # Remove any ```sql or ``` if present without proper formatting\n",
        "        query = re.sub(r'```sql|```', '', query).strip()\n",
        "\n",
        "    return {**item, 'sql': query}\n",
        "\n",
        "#Run agent on mode=nano, it's not needed to run on full dataset\n",
        "run_method(run_react_agent_with_config, SLEEP_TIME=20, mode=\"nano\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llms",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
