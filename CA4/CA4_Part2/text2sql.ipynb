{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "36ca5ad4",
      "metadata": {
        "id": "36ca5ad4"
      },
      "source": [
        "## CA 4 - Part 2, LLMs Spring 2025\n",
        "\n",
        "- **Name:**\n",
        "- **Student ID:**\n",
        "\n",
        "---\n",
        "#### Your submission should be named using the following format: `CA4_LASTNAME_STUDENTID.ipynb`.\n",
        "\n",
        "---\n",
        "\n",
        "TA Email: miladmohammadi@ut.ac.ir\n",
        "\n",
        "##### *How to do this problem set:*\n",
        "\n",
        "- Some questions require writing Python code and computing results, and the rest of them have written answers. For coding problems, you will have to fill out all code blocks that say `YOUR CODE HERE`.\n",
        "\n",
        "- For text-based answers, you should replace the text that says ```Your Answer Here``` with your actual answer.\n",
        "\n",
        "- There is no penalty for using AI assistance on this homework as long as you fully disclose it in the final cell of this notebook (this includes storing any prompts that you feed to large language models). That said, anyone caught using AI assistance without proper disclosure will receive a zero on the assignment (we have several automatic tools to detect such cases). We're literally allowing you to use it with no limitations, so there is no reason to lie!\n",
        "\n",
        "---\n",
        "\n",
        "##### *Academic honesty*\n",
        "\n",
        "- We will audit the Colab notebooks from a set number of students, chosen at random. The audits will check that the code you wrote actually generates the answers in your notebook. If you turn in correct answers on your notebook without code that actually generates those answers, we will consider this a serious case of cheating.\n",
        "\n",
        "- We will also run automatic checks of Colab notebooks for plagiarism. Copying code from others is also considered a serious case of cheating.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d86cccf5",
      "metadata": {
        "id": "d86cccf5"
      },
      "source": [
        "## Text2SQL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97c97a10",
      "metadata": {
        "id": "97c97a10"
      },
      "source": [
        "In this section, you will progressively build and evaluate multiple Text-to-SQL pipelines. You’ll start with a simple prompting-based baseline, then design a graph-based routing system using chain-of-thought and schema reasoning, and finally construct a ReAct agent that interacts with the schema via tools. Each stage demonstrates a different strategy for generating SQL from natural language using LLMs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86892463",
      "metadata": {
        "id": "86892463"
      },
      "source": [
        "### Initializations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e367a33b",
      "metadata": {
        "id": "e367a33b"
      },
      "source": [
        "This section prepares the environment and initializes the LLM model (Gemini) to be used in later parts of the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "079d57ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "079d57ea",
        "outputId": "cc4faeb2-b008-45db-cc13-b72730cfeefb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from -r requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: langchain in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from -r requirements.txt (line 2)) (0.3.27)\n",
            "Requirement already satisfied: langgraph in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from -r requirements.txt (line 3)) (0.6.1)\n",
            "Requirement already satisfied: langchain-core in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from -r requirements.txt (line 4)) (0.3.72)\n",
            "Requirement already satisfied: langchain-google-genai in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from -r requirements.txt (line 5)) (2.1.8)\n",
            "Requirement already satisfied: tqdm in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from -r requirements.txt (line 6)) (4.67.1)\n",
            "Requirement already satisfied: pandas in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from -r requirements.txt (line 7)) (2.2.3)\n",
            "Requirement already satisfied: func-timeout in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from -r requirements.txt (line 8)) (4.3.5)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (0.4.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (2.0.42)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langgraph->-r requirements.txt (line 3)) (2.1.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langgraph->-r requirements.txt (line 3)) (0.6.1)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.0 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langgraph->-r requirements.txt (line 3)) (0.2.0)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langgraph->-r requirements.txt (line 3)) (3.5.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langchain-core->-r requirements.txt (line 4)) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langchain-core->-r requirements.txt (line 4)) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langchain-core->-r requirements.txt (line 4)) (4.12.2)\n",
            "Requirement already satisfied: packaging>=23.2 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langchain-core->-r requirements.txt (line 4)) (24.2)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langchain-google-genai->-r requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langchain-google-genai->-r requirements.txt (line 5)) (0.6.18)\n",
            "Requirement already satisfied: colorama in c:\\users\\sazgar\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->-r requirements.txt (line 6)) (0.4.6)\n",
            "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from pandas->-r requirements.txt (line 7)) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from pandas->-r requirements.txt (line 7)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from pandas->-r requirements.txt (line 7)) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from pandas->-r requirements.txt (line 7)) (2025.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 5)) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 5)) (2.40.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 5)) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 5)) (6.31.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core->-r requirements.txt (line 4)) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph->-r requirements.txt (line 3)) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph->-r requirements.txt (line 3)) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph->-r requirements.txt (line 3)) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langsmith>=0.1.17->langchain->-r requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from langsmith>=0.1.17->langchain->-r requirements.txt (line 2)) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 2)) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 2)) (3.2.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 5)) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 5)) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 5)) (1.74.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 5)) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 5)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 5)) (4.9.1)\n",
            "Requirement already satisfied: anyio in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph->-r requirements.txt (line 3)) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph->-r requirements.txt (line 3)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph->-r requirements.txt (line 3)) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 5)) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\sazgar\\.conda\\envs\\llms\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph->-r requirements.txt (line 3)) (1.3.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d9f4a2c",
      "metadata": {
        "id": "9d9f4a2c"
      },
      "source": [
        "#### Load API Key (2 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "684e23a1",
      "metadata": {
        "id": "684e23a1"
      },
      "source": [
        "**Task:** Load the Gemini API key stored in the `.env` file and set it as an environment variable so it can be used to authenticate API requests later.\n",
        "\n",
        "* Use `dotenv` to load the file.\n",
        "* Extract the API key with `os.getenv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cd477695",
      "metadata": {
        "id": "cd477695"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
        "if not GOOGLE_API_KEY:\n",
        "  raise ValueError(\"GOOGLE_API_KEY not found in .env file or environment variable\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87ce1714",
      "metadata": {
        "id": "87ce1714"
      },
      "source": [
        "#### Create ChatModel (3 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b50a6f5",
      "metadata": {
        "id": "3b50a6f5"
      },
      "source": [
        "**Task:** Create an instance of the Gemini LLM using LangChain. You should configure the model with proper parameters for our task.\n",
        "\n",
        "Note: You may use any model that supports Structured Output and Tool Use. We recommend using gemini-2.5-flash-preview-05-20 from Google AI Studio, as it offers a generous free tier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c117040d",
      "metadata": {
        "id": "c117040d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sazgar\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3553: UserWarning: Parameters {'model', 'max_output_tokens', 'temperature'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "gemini_param = {\n",
        "    \"model\": \"gemini-2.5-flash-preview-05-20\",\n",
        "    \"temperature\": 0.01,\n",
        "    \"max_output_tokens\": 512,\n",
        "\n",
        "}\n",
        "# Create an instance of the Gemini LLM\n",
        "llm = ChatGoogleGenerativeAI(model_kwargs=gemini_param, google_api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "NQCVD1nBlndW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQCVD1nBlndW",
        "outputId": "79d6ad12-5692-450d-da27-e0a9f449f080"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Meow!', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'models/gemini-2.5-flash-preview-05-20', 'safety_ratings': []}, id='run--8e0cb2aa-081a-4027-ae87-10eb942529db-0', usage_metadata={'input_tokens': 6, 'output_tokens': 33, 'total_tokens': 39, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 30}})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(\"just say Meow!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8440112",
      "metadata": {
        "id": "e8440112"
      },
      "source": [
        "### Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "588c1c0b",
      "metadata": {
        "id": "588c1c0b"
      },
      "source": [
        "In this section, you'll build a simple baseline pipeline that directly converts a question and schema into a SQL query using a single prompt."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abef3ecf",
      "metadata": {
        "id": "abef3ecf"
      },
      "source": [
        "#### Baseline Function (5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7452b396",
      "metadata": {
        "id": "7452b396"
      },
      "source": [
        "\n",
        "**Task:** Implement a function that sends a system message defining the task, and a user message containing the input question and schema. The LLM should return the SQL query formatted as: \"```sql\\n[query]```\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0fd0eb1c",
      "metadata": {
        "id": "0fd0eb1c"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "def run_baseline(question: str, schema: str):\n",
        "    sys_msg = \"\"\"\n",
        "    ### TASK DESCRIPTION\n",
        "    You are an expert systems that receives a user's question and a database schema. \\\n",
        "    Generate a SQL query that answers the question.\n",
        "\n",
        "    ### FORMAT\n",
        "    formatted as a markdown SQL code block:\\n\n",
        "    ```sql\n",
        "    [query]\n",
        "    ```\n",
        "    \"\"\"\n",
        "    user_msg = f\"\"\"\n",
        "    Question: {question}\\n\n",
        "    Schema:\\n{schema}\\n\n",
        "    Only generate the SQL query, nothing else.\n",
        "    \"\"\"\n",
        "\n",
        "    messages = [\n",
        "        SystemMessage(content=sys_msg),\n",
        "        HumanMessage(content=user_msg)\n",
        "    ]\n",
        "\n",
        "    response = llm.invoke(messages)\n",
        "    sql_query = response.content\n",
        "\n",
        "    return sql_query"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b335cbd8",
      "metadata": {
        "id": "b335cbd8"
      },
      "source": [
        "#### Run and Evaluate (Estimated Run Time 5-10min)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f328a0c2",
      "metadata": {
        "id": "f328a0c2"
      },
      "source": [
        "Run your baseline function over the dataset provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "538878ae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "538878ae",
        "outputId": "74a7c6aa-214d-4b94-a9c2-713a23d27469"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/18 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Find the percentage of atoms with single bond. (Evidence: single bond refers to bond_type = '-'; percentage = DIVIDE(SUM(bond_type = '-'), COUNT(bond_id)) as percentage)\n",
            "Schema: atom (atom_id, molecule_id, element)\n",
            "bond (bond_id, molecule_id, bond_type)\n",
            "connected (atom_id, atom_id2, bond_id)\n",
            "molecule (molecule_id, label)\n",
            "\n",
            "Generated SQL: SELECT\n",
            "  CAST(SUM(CASE WHEN bond_type = '-' THEN 1 ELSE 0 END) AS REAL) * 100 / COUNT(bond_id)\n",
            "FROM bond;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 1/18 [00:11<03:09, 11.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Indicate which atoms are connected in non-carcinogenic type molecules. (Evidence: label = '-' means molecules are non-carcinogenic)\n",
            "Schema: atom (atom_id, molecule_id, element)\n",
            "bond (bond_id, molecule_id, bond_type)\n",
            "connected (atom_id, atom_id2, bond_id)\n",
            "molecule (molecule_id, label)\n",
            "\n",
            "Generated SQL: SELECT\n",
            "  T1.atom_id,\n",
            "  T1.atom_id2\n",
            "FROM connected AS T1\n",
            "INNER JOIN bond AS T2\n",
            "  ON T1.bond_id = T2.bond_id\n",
            "INNER JOIN molecule AS T3\n",
            "  ON T2.molecule_id = T3.molecule_id\n",
            "WHERE\n",
            "  T3.label = '-';\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 2/18 [00:23<03:06, 11.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What is the average number of bonds the atoms with the element iodine have? (Evidence: atoms with the element iodine refers to element = 'i'; average = DIVIDE(COUND(bond_id), COUNT(atom_id)) where element = 'i')\n",
            "Schema: atom (atom_id, molecule_id, element)\n",
            "bond (bond_id, molecule_id, bond_type)\n",
            "connected (atom_id, atom_id2, bond_id)\n",
            "molecule (molecule_id, label)\n",
            "\n",
            "Generated SQL: \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 3/18 [00:36<03:03, 12.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: List down two molecule id of triple bond non carcinogenic molecules with element carbon. (Evidence: carbon refers to element = 'c'; triple bond refers to bond_type = '#'; label = '-' means molecules are non-carcinogenic)\n",
            "Schema: atom (atom_id, molecule_id, element)\n",
            "bond (bond_id, molecule_id, bond_type)\n",
            "connected (atom_id, atom_id2, bond_id)\n",
            "molecule (molecule_id, label)\n",
            "\n",
            "Generated SQL: SELECT DISTINCT\n",
            "  T1.molecule_id\n",
            "FROM molecule AS T1\n",
            "INNER JOIN bond AS T2\n",
            "  ON T1.molecule_id = T2.molecule_id\n",
            "INNER JOIN atom AS T3\n",
            "  ON T1.molecule_id = T3.molecule_id\n",
            "WHERE\n",
            "  T2.bond_type = '#' AND T3.element = 'c' AND T1.label = '-'\n",
            "LIMIT 2;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 4/18 [00:47<02:49, 12.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What are the elements of the toxicology and label of molecule TR060? (Evidence: TR060 is the molecule id; label = '+' mean molecules are carcinogenic; label = '-' means molecules are non-carcinogenic; element = 'cl' means Chlorine; element = 'c' means Carbon; element = 'h' means Hydrogen; element = 'o' means Oxygen, element = 's' means Sulfur; element = 'n' means Nitrogen, element = 'p' means Phosphorus, element = 'na' means Sodium, element = 'br' means Bromine, element = 'f' means Fluorine; element = 'i' means Iodine; element = 'sn' means Tin; element = 'pb' means Lead; element = 'te' means Tellurium; element = 'ca' means Calcium)\n",
            "Schema: atom (atom_id, molecule_id, element)\n",
            "bond (bond_id, molecule_id, bond_type)\n",
            "connected (atom_id, atom_id2, bond_id)\n",
            "molecule (molecule_id, label)\n",
            "\n",
            "Generated SQL: SELECT T1.element, T2.label\n",
            "FROM atom AS T1\n",
            "INNER JOIN molecule AS T2\n",
            "  ON T1.molecule_id = T2.molecule_id\n",
            "WHERE\n",
            "  T1.molecule_id = 'TR060';\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 5/18 [00:58<02:32, 11.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What are the elements for bond id TR001_10_11? (Evidence: element = 'cl' means Chlorine; element = 'c' means Carbon; element = 'h' means Hydrogen; element = 'o' means Oxygen, element = 's' means Sulfur; element = 'n' means Nitrogen, element = 'p' means Phosphorus, element = 'na' means Sodium, element = 'br' means Bromine, element = 'f' means Fluorine; element = 'i' means Iodine; element = 'sn' means Tin; element = 'pb' means Lead; element = 'te' means Tellurium; element = 'ca' means Calcium)\n",
            "Schema: atom (atom_id, molecule_id, element)\n",
            "bond (bond_id, molecule_id, bond_type)\n",
            "connected (atom_id, atom_id2, bond_id)\n",
            "molecule (molecule_id, label)\n",
            "\n",
            "Generated SQL: SELECT DISTINCT T3.element\n",
            "FROM bond AS T1\n",
            "INNER JOIN connected AS T2\n",
            "  ON T1.bond_id = T2.bond_id\n",
            "INNER JOIN atom AS T3\n",
            "  ON T2.atom_id = T3.atom_id OR T2.atom_id2 = T3.atom_id\n",
            "WHERE\n",
            "  T1.bond_id = 'TR001_10_11';\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 6/18 [01:12<02:27, 12.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: How many superheroes were published by Dark Horse Comics? (Evidence: published by Dark Horse Comics refers to publisher_name = 'Dark Horse Comics';)\n",
            "Schema: alignment (id, alignment)\n",
            "attribute (id, attribute_name)\n",
            "colour (id, colour)\n",
            "gender (id, gender)\n",
            "publisher (id, publisher_name)\n",
            "race (id, race)\n",
            "superhero (id, superhero_name, full_name, gender_id, eye_colour_id, hair_colour_id, skin_colour_id, race_id, publisher_id, alignment_id, height_cm, weight_kg)\n",
            "hero_attribute (hero_id, attribute_id, attribute_value)\n",
            "superpower (id, power_name)\n",
            "hero_power (hero_id, power_id)\n",
            "\n",
            "Generated SQL: SELECT\n",
            "  COUNT(s.id)\n",
            "FROM superhero AS s\n",
            "JOIN publisher AS p\n",
            "  ON s.publisher_id = p.id\n",
            "WHERE\n",
            "  p.publisher_name = 'Dark Horse Comics';\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▉      | 7/18 [01:23<02:10, 11.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What are the race and alignment of Cameron Hicks? (Evidence: Cameron Hicks refers to superhero_name = 'Cameron Hicks';)\n",
            "Schema: alignment (id, alignment)\n",
            "attribute (id, attribute_name)\n",
            "colour (id, colour)\n",
            "gender (id, gender)\n",
            "publisher (id, publisher_name)\n",
            "race (id, race)\n",
            "superhero (id, superhero_name, full_name, gender_id, eye_colour_id, hair_colour_id, skin_colour_id, race_id, publisher_id, alignment_id, height_cm, weight_kg)\n",
            "hero_attribute (hero_id, attribute_id, attribute_value)\n",
            "superpower (id, power_name)\n",
            "hero_power (hero_id, power_id)\n",
            "\n",
            "Generated SQL: SELECT\n",
            "  T2.race,\n",
            "  T3.alignment\n",
            "FROM superhero AS T1\n",
            "INNER JOIN race AS T2\n",
            "ON T1.race_id = T2.id\n",
            "INNER JOIN alignment AS T3\n",
            "ON T1.alignment_id = T3.id\n",
            "WHERE\n",
            "  T1.superhero_name = 'Cameron Hicks';\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 8/18 [01:35<01:58, 11.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Among the superheroes with height from 170 to 190, list the names of the superheroes with no eye color. (Evidence: height from 170 to 190 refers to height_cm BETWEEN 170 AND 190; no eye color refers to eye_colour_id = 1)\n",
            "Schema: alignment (id, alignment)\n",
            "attribute (id, attribute_name)\n",
            "colour (id, colour)\n",
            "gender (id, gender)\n",
            "publisher (id, publisher_name)\n",
            "race (id, race)\n",
            "superhero (id, superhero_name, full_name, gender_id, eye_colour_id, hair_colour_id, skin_colour_id, race_id, publisher_id, alignment_id, height_cm, weight_kg)\n",
            "hero_attribute (hero_id, attribute_id, attribute_value)\n",
            "superpower (id, power_name)\n",
            "hero_power (hero_id, power_id)\n",
            "\n",
            "Generated SQL: SELECT superhero_name\n",
            "FROM superhero\n",
            "WHERE height_cm BETWEEN 170 AND 190 AND eye_colour_id = 1;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 9/18 [01:46<01:45, 11.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: List down at least five superpowers of male superheroes. (Evidence: male refers to gender = 'Male'; superpowers refers to power_name;)\n",
            "Schema: alignment (id, alignment)\n",
            "attribute (id, attribute_name)\n",
            "colour (id, colour)\n",
            "gender (id, gender)\n",
            "publisher (id, publisher_name)\n",
            "race (id, race)\n",
            "superhero (id, superhero_name, full_name, gender_id, eye_colour_id, hair_colour_id, skin_colour_id, race_id, publisher_id, alignment_id, height_cm, weight_kg)\n",
            "hero_attribute (hero_id, attribute_id, attribute_value)\n",
            "superpower (id, power_name)\n",
            "hero_power (hero_id, power_id)\n",
            "\n",
            "Generated SQL: SELECT DISTINCT\n",
            "  sp.power_name\n",
            "FROM superpower AS sp\n",
            "JOIN hero_power AS hp\n",
            "  ON sp.id = hp.power_id\n",
            "JOIN superhero AS sh\n",
            "  ON hp.hero_id = sh.id\n",
            "JOIN gender AS g\n",
            "  ON sh.gender_id = g.id\n",
            "WHERE\n",
            "  g.gender = 'Male'\n",
            "LIMIT 5;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 10/18 [01:58<01:32, 11.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What is the percentage of superheroes who act in their own self-interest or make decisions based on their own moral code? Indicate how many of the said superheroes were published by Marvel Comics. (Evidence: published by Marvel Comics refers to publisher_name = 'Marvel Comics'; superheroes who act in their own self-interest or make decisions based on their own moral code refers to alignment = 'Bad'; calculation = MULTIPLY(DIVIDE(SUM(alignment = 'Bad); count(id)), 100))\n",
            "Schema: alignment (id, alignment)\n",
            "attribute (id, attribute_name)\n",
            "colour (id, colour)\n",
            "gender (id, gender)\n",
            "publisher (id, publisher_name)\n",
            "race (id, race)\n",
            "superhero (id, superhero_name, full_name, gender_id, eye_colour_id, hair_colour_id, skin_colour_id, race_id, publisher_id, alignment_id, height_cm, weight_kg)\n",
            "hero_attribute (hero_id, attribute_id, attribute_value)\n",
            "superpower (id, power_name)\n",
            "hero_power (hero_id, power_id)\n",
            "\n",
            "Generated SQL: SELECT\n",
            "  (\n",
            "    COUNT(CASE WHEN T2.alignment = 'Bad' THEN T1.id END) * 100.0\n",
            "  ) / COUNT(T1.id) AS percentage_bad_alignment,\n",
            "  COUNT(\n",
            "    CASE WHEN T2.alignment = 'Bad' AND T3.publisher_name = 'Marvel Comics' THEN T1.id END\n",
            "  ) AS marvel_bad_alignment_count\n",
            "FROM superhero AS T1\n",
            "INNER JOIN alignment AS T2\n",
            "  ON T1.alignment_id = T2.id\n",
            "LEFT JOIN publisher AS T3\n",
            "  ON T1.publisher_id = T3.id;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████    | 11/18 [02:11<01:25, 12.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Which publisher created more superheroes: DC or Marvel Comics? Find the difference in the number of superheroes. (Evidence: DC refers to publisher_name = 'DC Comics'; Marvel Comics refers to publisher_name = 'Marvel Comics'; if SUM(publisher_name = 'DC Comics') > SUM(publisher_name = 'Marvel Comics'), it means DC Comics published more superheroes than Marvel Comics; if SUM(publisher_name = 'Marvel Comics') > SUM(publisher_name = 'Marvel Comics'), it means Marvel Comics published more heroes than DC Comics; difference = SUBTRACT(SUM(publisher_name = 'DC Comics'), SUM(publisher_name = 'Marvel Comics'));)\n",
            "Schema: alignment (id, alignment)\n",
            "attribute (id, attribute_name)\n",
            "colour (id, colour)\n",
            "gender (id, gender)\n",
            "publisher (id, publisher_name)\n",
            "race (id, race)\n",
            "superhero (id, superhero_name, full_name, gender_id, eye_colour_id, hair_colour_id, skin_colour_id, race_id, publisher_id, alignment_id, height_cm, weight_kg)\n",
            "hero_attribute (hero_id, attribute_id, attribute_value)\n",
            "superpower (id, power_name)\n",
            "hero_power (hero_id, power_id)\n",
            "\n",
            "Generated SQL: \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 12/18 [02:24<01:14, 12.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Who was the first one paid his/her dues? Tell the full name. (Evidence: full name refers to first_name, last_name; first paid dues refers to MIN(received_date) where source = 'Dues')\n",
            "Schema: event (event_id, event_name, event_date, type, notes, location, status)\n",
            "major (major_id, major_name, department, college)\n",
            "zip_code (zip_code, type, city, county, state, short_state)\n",
            "attendance (link_to_event, link_to_member)\n",
            "budget (budget_id, category, spent, remaining, amount, event_status, link_to_event)\n",
            "expense (expense_id, expense_description, expense_date, cost, approved, link_to_member, link_to_budget)\n",
            "income (income_id, date_received, amount, source, notes, link_to_member)\n",
            "member (member_id, first_name, last_name, email, position, t_shirt_size, phone, zip, link_to_major)\n",
            "\n",
            "Generated SQL: SELECT\n",
            "  T1.first_name,\n",
            "  T1.last_name\n",
            "FROM member AS T1\n",
            "INNER JOIN income AS T2\n",
            "  ON T1.member_id = T2.link_to_member\n",
            "WHERE\n",
            "  T2.source = 'Dues' AND T2.date_received = (\n",
            "    SELECT\n",
            "      MIN(date_received)\n",
            "    FROM income\n",
            "    WHERE\n",
            "      source = 'Dues'\n",
            "  );\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 13/18 [02:37<01:02, 12.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: How many income are received with an amount of 50? (Evidence: amount of 50 refers to amount = 50)\n",
            "Schema: event (event_id, event_name, event_date, type, notes, location, status)\n",
            "major (major_id, major_name, department, college)\n",
            "zip_code (zip_code, type, city, county, state, short_state)\n",
            "attendance (link_to_event, link_to_member)\n",
            "budget (budget_id, category, spent, remaining, amount, event_status, link_to_event)\n",
            "expense (expense_id, expense_description, expense_date, cost, approved, link_to_member, link_to_budget)\n",
            "income (income_id, date_received, amount, source, notes, link_to_member)\n",
            "member (member_id, first_name, last_name, email, position, t_shirt_size, phone, zip, link_to_major)\n",
            "\n",
            "Generated SQL: SELECT\n",
            "  COUNT(income_id)\n",
            "FROM income\n",
            "WHERE\n",
            "  amount = 50;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 14/18 [02:48<00:48, 12.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Name the event with the highest amount spent on advertisement. (Evidence: event refers to event_name; highest amount spent on advertisement refers to MAX(spent) where category = 'Advertisement')\n",
            "Schema: event (event_id, event_name, event_date, type, notes, location, status)\n",
            "major (major_id, major_name, department, college)\n",
            "zip_code (zip_code, type, city, county, state, short_state)\n",
            "attendance (link_to_event, link_to_member)\n",
            "budget (budget_id, category, spent, remaining, amount, event_status, link_to_event)\n",
            "expense (expense_id, expense_description, expense_date, cost, approved, link_to_member, link_to_budget)\n",
            "income (income_id, date_received, amount, source, notes, link_to_member)\n",
            "member (member_id, first_name, last_name, email, position, t_shirt_size, phone, zip, link_to_major)\n",
            "\n",
            "Generated SQL: SELECT\n",
            "  T1.event_name\n",
            "FROM event AS T1\n",
            "INNER JOIN budget AS T2\n",
            "  ON T1.event_id = T2.link_to_event\n",
            "WHERE\n",
            "  T2.category = 'Advertisement'\n",
            "ORDER BY\n",
            "  T2.spent DESC\n",
            "LIMIT 1;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 15/18 [02:59<00:35, 11.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Based on the total cost for all event, what is the percentage of cost for Yearly Kickoff event? (Evidence: DIVIDE(SUM(cost where event_name = 'Yearly Kickoff'), SUM(cost)) * 100)\n",
            "Schema: event (event_id, event_name, event_date, type, notes, location, status)\n",
            "major (major_id, major_name, department, college)\n",
            "zip_code (zip_code, type, city, county, state, short_state)\n",
            "attendance (link_to_event, link_to_member)\n",
            "budget (budget_id, category, spent, remaining, amount, event_status, link_to_event)\n",
            "expense (expense_id, expense_description, expense_date, cost, approved, link_to_member, link_to_budget)\n",
            "income (income_id, date_received, amount, source, notes, link_to_member)\n",
            "member (member_id, first_name, last_name, email, position, t_shirt_size, phone, zip, link_to_major)\n",
            "\n",
            "Generated SQL: SELECT\n",
            "  SUM(CASE WHEN T3.event_name = 'Yearly Kickoff' THEN T1.cost ELSE 0 END) * 100.0 / SUM(T1.cost)\n",
            "FROM expense AS T1\n",
            "INNER JOIN budget AS T2\n",
            "  ON T1.link_to_budget = T2.budget_id\n",
            "INNER JOIN event AS T3\n",
            "  ON T2.link_to_event = T3.event_id;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 89%|████████▉ | 16/18 [03:11<00:23, 11.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Calculate the total average cost that Elijah Allen spent in the events on September and October. (Evidence: events in September and October refers to month(expense_date) = 9 AND MONTH(expense_date) = 10)\n",
            "Schema: event (event_id, event_name, event_date, type, notes, location, status)\n",
            "major (major_id, major_name, department, college)\n",
            "zip_code (zip_code, type, city, county, state, short_state)\n",
            "attendance (link_to_event, link_to_member)\n",
            "budget (budget_id, category, spent, remaining, amount, event_status, link_to_event)\n",
            "expense (expense_id, expense_description, expense_date, cost, approved, link_to_member, link_to_budget)\n",
            "income (income_id, date_received, amount, source, notes, link_to_member)\n",
            "member (member_id, first_name, last_name, email, position, t_shirt_size, phone, zip, link_to_major)\n",
            "\n",
            "Generated SQL: SELECT\n",
            "  AVG(T1.cost)\n",
            "FROM expense AS T1\n",
            "INNER JOIN member AS T2\n",
            "  ON T1.link_to_member = T2.member_id\n",
            "WHERE\n",
            "  T2.first_name = 'Elijah' AND T2.last_name = 'Allen' AND (\n",
            "    STRFTIME('%m', T1.expense_date) = '09' OR STRFTIME('%m', T1.expense_date) = '10'\n",
            "  );\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 17/18 [03:23<00:11, 11.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Find the name and date of events with expenses for pizza that were more than fifty dollars but less than a hundred dollars. (Evidence: name of event refers to event_name; date of event refers to event_date; expenses for pizza refers to expense_description = 'Pizza' where cost > 50 and cost < 100)\n",
            "Schema: event (event_id, event_name, event_date, type, notes, location, status)\n",
            "major (major_id, major_name, department, college)\n",
            "zip_code (zip_code, type, city, county, state, short_state)\n",
            "attendance (link_to_event, link_to_member)\n",
            "budget (budget_id, category, spent, remaining, amount, event_status, link_to_event)\n",
            "expense (expense_id, expense_description, expense_date, cost, approved, link_to_member, link_to_budget)\n",
            "income (income_id, date_received, amount, source, notes, link_to_member)\n",
            "member (member_id, first_name, last_name, email, position, t_shirt_size, phone, zip, link_to_major)\n",
            "\n",
            "Generated SQL: SELECT\n",
            "  T1.event_name,\n",
            "  T1.event_date\n",
            "FROM event AS T1\n",
            "INNER JOIN budget AS T2\n",
            "  ON T1.event_id = T2.link_to_event\n",
            "INNER JOIN expense AS T3\n",
            "  ON T2.budget_id = T3.link_to_budget\n",
            "WHERE\n",
            "  T3.expense_description = 'Pizza' AND T3.cost > 50 AND T3.cost < 100;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [03:35<00:00, 11.95s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting to compare without knowledge for ex\n",
            "Process finished successfully\n",
            "start calculate\n",
            "                     simple               moderate             challenging          total               \n",
            "count                6                    6                    6                    18                  \n",
            "======================================    ACCURACY    =====================================\n",
            "accuracy             66.67                83.33                83.33                77.78               \n",
            "===========================================================================================\n",
            "Finished evaluation\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from method_run import run_method\n",
        "import re\n",
        "\n",
        "def function_template(item):\n",
        "    result = run_baseline(item['question'], item['schema'])\n",
        "    # First try to extract query from markdown SQL block\n",
        "    match = re.search(r'```sql\\n(.*?)```', result, re.DOTALL)\n",
        "    if match:\n",
        "        query = match.group(1).strip()\n",
        "    else:\n",
        "        # If no markdown block found, try to extract just SQL query\n",
        "        query = result.strip()\n",
        "        # Remove any ```sql or ``` if present without proper formatting\n",
        "        query = re.sub(r'```sql|```', '', query).strip()\n",
        "\n",
        "    print(f\"Question: {item['question']}\")\n",
        "    print(f\"Schema: {item['schema']}\")\n",
        "    print(f\"Generated SQL: {query}\\n\")\n",
        "\n",
        "    return {**item, 'sql': query}\n",
        "\n",
        "run_method(function_template, SLEEP_TIME=10)\n",
        "\n",
        "#Run on mode=nano if you want to test it on a smaller dataset\n",
        "#run_method(function_template, SLEEP_TIME=10, mode=\"nano\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4cd06f9",
      "metadata": {
        "id": "f4cd06f9"
      },
      "source": [
        "### Chain/Router"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f46affa4",
      "metadata": {
        "id": "f46affa4"
      },
      "source": [
        "Here, you will build a more advanced system that routes the query through different paths based on question difficulty. Easier questions go straight to query generation; harder ones go through schema path extraction first."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afa254aa",
      "metadata": {
        "id": "afa254aa"
      },
      "source": [
        "#### Define State (5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a7db5cc",
      "metadata": {
        "id": "6a7db5cc"
      },
      "source": [
        "**Task:** Define a `RouterGraphState` using `MessagesState` and `pydantic` that contains:\n",
        "* The input question and schema\n",
        "* The predicted difficulty level\n",
        "* The extracted schema path\n",
        "* The final query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d65c044e",
      "metadata": {
        "id": "d65c044e"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import MessagesState\n",
        "from typing import Literal, Optional\n",
        "from pydantic import Field\n",
        "\n",
        "class RouterGraphState(MessagesState):\n",
        "    question: str = Field(\n",
        "        ..., \n",
        "        title=\"User Question\", \n",
        "        description=\"The natural language question that needs to be converted into an SQL query.\"\n",
        "    )\n",
        "    \n",
        "    schema: str = Field(\n",
        "        ..., \n",
        "        title=\"Database Schema\", \n",
        "        description=\"The full database schema context provided to the LLM.\"\n",
        "    )\n",
        "    \n",
        "    question_difficulty: Literal[\"simple\", \"moderate\", \"challanging\"] = Field(\n",
        "        ..., \n",
        "        title=\"Question Difficulty\",\n",
        "        description=\"Classification of the question's difficulty used to determine the query generation path.\"\n",
        "    )\n",
        "    \n",
        "    schema_path: Optional[str] = Field(\n",
        "        default=None,\n",
        "        title=\"Extracted Schema Path\",\n",
        "        description=\"The relevant subset of the schema used for query generation when the question is classified as hard.\"\n",
        "    )\n",
        "    \n",
        "    query: Optional[str] = Field(\n",
        "        default=None,\n",
        "        title=\"Generated SQL Query\",\n",
        "        description=\"The final SQL query generated based on the question and schema.\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "696dc1c9",
      "metadata": {
        "id": "696dc1c9"
      },
      "source": [
        "#### Node: Analyser (5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "971ace53",
      "metadata": {
        "id": "971ace53"
      },
      "source": [
        "**Task:** Build a node that:\n",
        "* Accepts a question and schema\n",
        "* Analyzes the difficulty (simple/moderate/challanging)\n",
        "* Uses the LLM’s structured output feature to return the difficulty\n",
        "\n",
        "**Steps**:\n",
        "\n",
        "1. Define a Pydantic class to hold the expected structured output.\n",
        "2. Use structure output mode of LLM to bind it to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a1969dbc",
      "metadata": {
        "id": "a1969dbc"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class QuestionDifficaultyAnalysis(BaseModel):\n",
        "    question_difficulty: Literal[\"simple\", \"moderate\", \"challanging\"] = Field(\n",
        "        ..., \n",
        "        title=\"Question Difficulty Level\",\n",
        "        description=(\n",
        "            \"The estimated difficulty of the SQL question. \"\n",
        "            \"'simple' means a direct query on one table with no joins or aggregation. \"\n",
        "            \"'moderate' may require joins or basic filters. \"\n",
        "            \"'challenging' involves complex logic, multiple joins, nested queries, or interpretation of intent.\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    reasoning: str = Field(\n",
        "        ..., \n",
        "        title=\"Reasoning\",\n",
        "        description=\"Brief explanation of why this difficulty was assigned.\"\n",
        "    )\n",
        "\n",
        "def analyser_node(state: RouterGraphState):\n",
        "    sys_msg = SystemMessage(\n",
        "        content=\"\"\"\n",
        "        ### TASK DESCRIPTION\n",
        "            You are an expert system that analyzes a user's natural language question and a database schema.\n",
        "            Your sole task is to classify the question's difficulty level as one of: \"simple\", \"moderate\", or \"challanging\".\n",
        "\n",
        "            Judge the difficulty based on the following criteria:\n",
        "            - **Simple:** The query requires only one or two tables, straightforward filters (WHERE clauses), and basic aggregations (COUNT, SUM, AVG) without complex joins or nested queries.\n",
        "            - **Moderate:** The query requires multiple tables, involves JOIN operations, might include more complex filtering, basic grouping (GROUP BY), or simple ORDER BY clauses.\n",
        "            - **Challenging:** The query involves multiple complex JOINs, subqueries, complex aggregations, conditional logic (CASE statements), or advanced SQL functions/patterns.\n",
        "\n",
        "            Your response must be a JSON object containing two keys:\n",
        "            1. \"question_difficulty\" with the classified value (\"simple\" | \"moderate\" | \"challanging\").\n",
        "            2. \"reasoning\" with a brief explanation of *why* this difficulty was assigned, referencing the criteria.\n",
        "\n",
        "        ### FORMAT\n",
        "            ```json\n",
        "            {\"question_difficulty\": \"simple\" | \"moderate\" | \"challanging\", \"reasoning\": \"Explanation here...\"}\n",
        "            ```\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    user_msg = HumanMessage(\n",
        "        content=f\"\"\"\n",
        "        ### Question\n",
        "        {state.question}\\n\n",
        "        ### Schema\n",
        "        {state.schema}\\n\n",
        "        Only generate the JSON object, nothing else.\n",
        "        \"\"\"\n",
        "    )\n",
        "    messages = [sys_msg, user_msg]\n",
        "    llm_struct = llm.with_structured_output(QuestionDifficaultyAnalysis)\n",
        "    response = llm_struct.invoke(messages)\n",
        "    state.question_difficulty = response.question_difficulty\n",
        "    return state"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f78d38c",
      "metadata": {
        "id": "9f78d38c"
      },
      "source": [
        "#### Conditional Edge (2 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "406d17e0",
      "metadata": {
        "id": "406d17e0"
      },
      "source": [
        "**Task:** Implement a branching function that decides whether to proceed to direct query generation or schema path extraction based on the difficulty label returned by the analyser.\n",
        "\n",
        "* If the difficulty is “easy”, go directly to query generation.\n",
        "* Otherwise, extract the schema path first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "908afa3c",
      "metadata": {
        "id": "908afa3c"
      },
      "outputs": [],
      "source": [
        "def is_schema_extraction_needed(state: RouterGraphState) -> Literal[\"schema_path_extractor\", \"query_generator\"]:\n",
        "    \"\"\"\n",
        "    Routing decision function for LangGraph.\n",
        "\n",
        "    Determines the next processing step based on the predicted difficulty level of the question.\n",
        "\n",
        "    Returns:\n",
        "        - \"query_generator\": for simple questions that require no schema reduction.\n",
        "        - \"schema_path_extractor\": for moderate or challenging questions that benefit from targeted schema focus.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the difficulty label is missing or invalid.\n",
        "    \"\"\"\n",
        "\n",
        "    difficulty = state.question_difficulty \n",
        "    \n",
        "    if state.schema_path is not None:\n",
        "        return \"query_generator\" \n",
        "\n",
        "    if not isinstance(difficulty, str):\n",
        "        raise TypeError(\"Difficulty must be a string literal ('simple', 'moderate', or 'challenging').\") \n",
        "\n",
        "    difficulty_normalized = difficulty.strip().lower() \n",
        "\n",
        "    if difficulty_normalized == \"simple\":\n",
        "        return \"query_generator\"\n",
        "\n",
        "    elif difficulty_normalized in {\"moderate\", \"challenging\"}:\n",
        "        return \"schema_path_extractor\"\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            f\"Unrecognized difficulty label: '{difficulty}'. \"\n",
        "            \"Expected one of: 'simple', 'moderate', 'challenging'.\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "108c9d25",
      "metadata": {
        "id": "108c9d25"
      },
      "source": [
        "#### Node: Schema Extractor (3 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e159a0f9",
      "metadata": {
        "id": "e159a0f9"
      },
      "source": [
        "**Task:** Implement a node that takes the question and schema and extracts a join path or sequence of relevant tables from the schema based on the question.\n",
        "\n",
        "* Use a simple prompt for this.\n",
        "* Store the result in the `schema_path` field of the state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "598a057f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import Runnable\n",
        "\n",
        "schema_path_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\n",
        "            \"system\",\n",
        "            \"You are a SQL database schema extraction specialist. Your ONLY task is to identify and return the exact table schemas needed to answer the user's question.\\n\\n\"\n",
        "            \n",
        "            \"EXTRACTION RULES:\\n\"\n",
        "            \"1. Analyze the question to identify which tables contain the data needed\\n\"\n",
        "            \"2. Include ALL columns from identified tables (do not filter columns)\\n\"\n",
        "            \"3. Include related tables connected by foreign keys\\n\"\n",
        "            \"4. Return and copy schemas in their EXACT original format\\n\"\n",
        "            \"5. If uncertain about relevance, include the table (better to over-include than miss required data)\\n\"\n",
        "            \"6. Never made up schemas which not exists! Pay attention fully to question details.\\n\\n\"\n",
        "            \"OUTPUT FORMAT:\\n\"\n",
        "            \"- TRY TO Return ONLY the relevant Schema based on information provided in question.\\n\"\n",
        "            \"- DO NOT wrap output in markdown code blocks (no ```sql or ``` tags)\\n\"\n",
        "            \"- DO NOT add any formatting markers or backticks\\n\"\n",
        "            \"- Return raw Schemas only\\n\"\n",
        "            \"- Preserve exact formatting, syntax, and structure\\n\"\n",
        "            \"- No explanations, comments, or additional text\\n\\n\"\n",
        "            \n",
        "            \"VALIDATION CHECKLIST:\\n\"\n",
        "            \"- Does the question mention specific table/column names? Include those tables\\n\"\n",
        "            \"- Are there JOIN operations implied? Include all related tables\\n\"\n",
        "            \"- Are there aggregations or filters mentioned? Include tables with those columns\\n\"\n",
        "            \"- Are there foreign key relationships? Include both parent and child tables\\n\\n\"\n",
        "            \n",
        "            \"ALWAYS return at least one table schema. If the question is unclear, include the most likely relevant tables rather than returning nothing.\"),\n",
        "    (\"human\",\n",
        "     \"### Question:\\n{question}\\n\\n### Schema:\\n{schema}\") \n",
        "])\n",
        "\n",
        "\n",
        "schema_path_extractor_chain: Runnable = schema_path_prompt | llm\n",
        "\n",
        "\n",
        "def schema_path_extractor_node(state: RouterGraphState) -> RouterGraphState:\n",
        "    \"\"\"\n",
        "    Extracts the subset of the schema relevant to the user's question.\n",
        "    This is used for complex questions that benefit from schema narrowing.\n",
        "    Updates: state.schema_path\n",
        "    \"\"\"\n",
        "    # Prepare and run prompt    \n",
        "    result = schema_path_extractor_chain.invoke({\n",
        "        \"question\": state.question.strip(),\n",
        "        \"schema\": state.schema.strip()\n",
        "    })\n",
        "    \n",
        "    # Sanitize and assign result\n",
        "    extracted = result.content.strip()\n",
        "    if not extracted:\n",
        "        print(\"Warning: Schema path extraction returned empty. Using full schema as fallback.\")\n",
        "        state.schema_path = state.schema\n",
        "    else:\n",
        "        state.schema_path = extracted\n",
        "    \n",
        "    return state"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "091dc790",
      "metadata": {
        "id": "091dc790"
      },
      "source": [
        "#### Node: Generator (5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f374e09",
      "metadata": {
        "id": "9f374e09"
      },
      "source": [
        "**Task:** Generate the SQL query based on the question and schema.\n",
        "\n",
        "* If a schema path is available, include it in the prompt.\n",
        "* Save the output query in the `query` field of the state.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3a600328",
      "metadata": {
        "id": "3a600328"
      },
      "outputs": [],
      "source": [
        "query_generation_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\n",
        "     \"\"\"\n",
        "     You are an **expert SQL query generator**. Your **ONLY** task is to generate the most accurate SQL query to answer the user's question, \\\n",
        "     using **STRICTLY** the provided schema and, if given, the relevant schema path.\n",
        "\n",
        "     ### APPLY these rules precisely:\n",
        "     - Use ONLY tables and columns present in the provided schema or schema path.\n",
        "     - Do NOT invent, rename, or hallucinate any schema elements.\n",
        "     - Use JOINs ONLY as needed, based on explicit foreign key relationships or clear requirements from the schema/path.\n",
        "     - If the question requires aggregation, grouping, subqueries, or ordering, reflect these precisely as per SQL syntax.\n",
        "     - For simple questions (as inferred from language or difficulty level), \\\n",
        "          use concise SQL and avoid unneeded complexity. For moderate/challenging questions, carefully write correct, \\\n",
        "               efficient, and clear multi-table, subquery, or CASE logic as per requirements.\n",
        "     - Do NOT output any prose, explanation, comments, or formatting markers—only the SQL query in the format below.\n",
        "\n",
        "     Output format:\n",
        "     ```sql\n",
        "     [YOUR_SQL_QUERY_HERE]\n",
        "     ```\n",
        "     \"\"\"),\n",
        "    (\"human\",\n",
        "     \"\"\"\n",
        "     #### Question\n",
        "     {question}\n",
        "\n",
        "     #### Schema\n",
        "     {schema}\n",
        "\n",
        "     {%- if schema_path and schema_path.strip() %}\n",
        "     #### Contextual Schema Information\n",
        "     {{ schema_path }}\n",
        "     {%- endif %}\n",
        "\n",
        "     Only return the final SQL query in the specified format.\n",
        "     \"\"\")\n",
        "])\n",
        "\n",
        "query_generation_chain: Runnable = query_generation_prompt | llm\n",
        "\n",
        "def query_generator_node(state: RouterGraphState):\n",
        "     \"\"\"\n",
        "    Generates the final SQL query based on the question, full schema,\n",
        "    and optionally, the extracted schema path for complex queries.\n",
        "    Updates: state.query\n",
        "    \"\"\"\n",
        "     # Prepare and run prompt\n",
        "     inputs = {\n",
        "          \"question\": state.question.strip(),\n",
        "          \"schema\": state.schema.strip(),\n",
        "          \"schema_path\": state.schema_path.strip() if state.schema_path else \"\"\n",
        "     }\n",
        "     result = query_generation_chain.invoke(inputs)\n",
        "     \n",
        "     # Sanitize and assign result\n",
        "     state.query = result.content.strip()\n",
        "     return state"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b20d96c",
      "metadata": {
        "id": "6b20d96c"
      },
      "source": [
        "#### Build Graph (5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0416b89b",
      "metadata": {
        "id": "0416b89b"
      },
      "source": [
        "**Task:** Assemble the full routing graph using the nodes and edges you created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f58c86e",
      "metadata": {
        "id": "3f58c86e"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START\n",
        "\n",
        "router_graph_builder = StateGraph(RouterGraphState)\n",
        "\n",
        "#YOUR CODE HERE\n",
        "\n",
        "router_graph = router_graph_builder.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "204fab8e",
      "metadata": {
        "id": "204fab8e"
      },
      "source": [
        "#### Run and Evaluate (Estimated Run Time 10-15min)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b90f0bc7",
      "metadata": {
        "id": "b90f0bc7"
      },
      "source": [
        "**Task:** Run your compiled routing graph on a dataset. For each question:\n",
        "\n",
        "* Instantiate the `RouterGraphState` with the question and schema.\n",
        "* Run the graph to completion.\n",
        "* Extract and clean the query from the result.\n",
        "\n",
        "Use the `run_method` function to handle iteration and timing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "585c706f",
      "metadata": {
        "id": "585c706f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/18 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'router_graph' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 31\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated SQL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mitem, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msql\u001b[39m\u001b[38;5;124m'\u001b[39m: query}\n\u001b[1;32m---> 31\u001b[0m \u001b[43mrun_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_router_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSLEEP_TIME\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#Run on mode=nano if you want to test it on a smaller dataset\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m#run_method(run_router_graph, SLEEP_TIME=10, mode=\"nano\")\u001b[39;00m\n",
            "File \u001b[1;32mf:\\UT\\LLMs\\UT\\HW\\CA4\\CA4_Part2\\method_run.py:21\u001b[0m, in \u001b[0;36mrun_method\u001b[1;34m(function_template, SLEEP_TIME, mode)\u001b[0m\n\u001b[0;32m     19\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m tqdm(data):\n\u001b[1;32m---> 21\u001b[0m     item_result \u001b[38;5;241m=\u001b[39m \u001b[43mfunction_template\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(item_result)\n\u001b[0;32m     23\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(SLEEP_TIME)\n",
            "Cell \u001b[1;32mIn[11], line 3\u001b[0m, in \u001b[0;36mrun_router_graph\u001b[1;34m(item)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_router_graph\u001b[39m(item):\n\u001b[1;32m----> 3\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrouter_graph\u001b[49m\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m      4\u001b[0m         RouterGraphState(\n\u001b[0;32m      5\u001b[0m             question\u001b[38;5;241m=\u001b[39mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      6\u001b[0m             schema\u001b[38;5;241m=\u001b[39mitem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mschema\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      7\u001b[0m             schema_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m      8\u001b[0m             question_difficulty\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m      9\u001b[0m             query\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     10\u001b[0m         )\n\u001b[0;32m     11\u001b[0m     )\n\u001b[0;32m     12\u001b[0m     result \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# First try to extract query from markdown SQL block\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'router_graph' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "from method_run import run_method\n",
        "def run_router_graph(item):\n",
        "    response = router_graph.invoke(\n",
        "        RouterGraphState(\n",
        "            question=item['question'],\n",
        "            schema=item['schema'],\n",
        "            schema_path=None,\n",
        "            question_difficulty=None,\n",
        "            query=None\n",
        "        )\n",
        "    )\n",
        "    result = response[\"query\"]\n",
        "    # First try to extract query from markdown SQL block\n",
        "    match = re.search(r'```sql\\n(.*?)```', result, re.DOTALL)\n",
        "    if match:\n",
        "        query = match.group(1).strip()\n",
        "    else:\n",
        "        # If no markdown block found, try to extract just SQL query\n",
        "        query = result.strip()\n",
        "        # Remove any ```sql or ``` if present without proper formatting\n",
        "        query = re.sub(r'```sql|```', '', query).strip()\n",
        "    print(f\"Question: {item['question']}\")\n",
        "    print(f\"Schema: {item['schema']}\")\n",
        "    print(f\"Question Difficulty: {response['question_difficulty']}\")\n",
        "    if response[\"schema_path\"]:\n",
        "        print(f\"Schema Path: {response['schema_path']}\")\n",
        "    print(f\"Generated SQL: {query}\\n\")\n",
        "    return {**item, 'sql': query}\n",
        "\n",
        "\n",
        "run_method(run_router_graph, SLEEP_TIME=30)\n",
        "\n",
        "#Run on mode=nano if you want to test it on a smaller dataset\n",
        "#run_method(run_router_graph, SLEEP_TIME=10, mode=\"nano\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4666dff4",
      "metadata": {
        "id": "4666dff4"
      },
      "source": [
        "### Agent (ReAct)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bc99580",
      "metadata": {
        "id": "5bc99580"
      },
      "source": [
        "Now you will implement a full ReAct agent that incrementally solves the Text-to-SQL task using tools. The agent can explore tables and columns before finalizing the query."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1df0a65",
      "metadata": {
        "id": "d1df0a65"
      },
      "source": [
        "**You are not allowed to use 'Prebuilt Agent' of LangGraph. You have to build your own graph.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9505b9f8",
      "metadata": {
        "id": "9505b9f8"
      },
      "source": [
        "#### Define Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07b3582a",
      "metadata": {
        "id": "07b3582a"
      },
      "source": [
        "**Task:** Define three tools for the agent to interact with the schema:\n",
        "1. `get_samples_from_table`: Returns the first few rows of a table.\n",
        "2. `get_column_description`: Provides a human-readable description of a specific column.\n",
        "3. `execute`: Executes a SQL query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4ab00e13",
      "metadata": {
        "id": "4ab00e13"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "from db_manager import DBManager\n",
        "db_manager = DBManager()\n",
        "\n",
        "@tool\n",
        "def get_samples_from_table(table_name: str, config: RunnableConfig):\n",
        "  \"\"\"Gets the first few rows (samples) from a specified table.\n",
        "\n",
        "  Args:\n",
        "    table_name: The name of the table from which to fetch samples.\n",
        "\n",
        "  Returns:\n",
        "    The first few rows from the specified table.\n",
        "  \"\"\"\n",
        "  db_name = config[\"configurable\"].get(\"database_name\")\n",
        "  result = db_manager.get_table_head(table_name, db_name=db_name)\n",
        "  return result\n",
        "\n",
        "@tool\n",
        "def get_column_description(table_name: str, column_name: str, config: RunnableConfig):\n",
        "  \"\"\"Provides a description for a specific column within a given table.\n",
        "\n",
        "  Args:\n",
        "    table_name: The name of the table containing the column.\n",
        "    column_name: The name of the column for which to get the description.\n",
        "\n",
        "  Returns:\n",
        "    A string containing the description of the specified column.\n",
        "  \"\"\"\n",
        "  db_name = config[\"configurable\"].get(\"database_name\")\n",
        "  result = db_manager.get_column_description(db_name, table_name, column_name)\n",
        "  return result\n",
        "\n",
        "@tool\n",
        "def execute(query: str, config: RunnableConfig):\n",
        "  \"\"\"Executes a given SQL query against the database.\n",
        "\n",
        "  Args:\n",
        "    query: The SQL query string to be executed.\n",
        "\n",
        "  Returns:\n",
        "    The result of the executed query. This could be a set of rows,\n",
        "    a confirmation message, or an error.\n",
        "  \"\"\"\n",
        "  db_name = config[\"configurable\"].get(\"database_name\")\n",
        "  result = db_manager.query(query, db_name)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66680244",
      "metadata": {
        "id": "66680244"
      },
      "source": [
        "#### Extra Tool (5+5 Bonus Points):"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f80baae9",
      "metadata": {
        "id": "f80baae9"
      },
      "source": [
        "**Task**: Create and integrate a new custom tool into the ReAct agent. To receive credit for this part, your tool must be meaningfully different from the existing three tools and provide practical value in helping the agent generate more accurate or efficient SQL queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c0308d9",
      "metadata": {
        "id": "7c0308d9"
      },
      "outputs": [],
      "source": [
        "#YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfbe11d0",
      "metadata": {
        "id": "cfbe11d0"
      },
      "source": [
        "#### Create Tool Node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b24a997",
      "metadata": {
        "id": "2b24a997"
      },
      "outputs": [],
      "source": [
        "tools = [get_samples_from_table, get_column_description, execute]\n",
        "tools_node = ToolNode(tools=tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8348623d",
      "metadata": {
        "id": "8348623d"
      },
      "source": [
        "#### ReAct Agent Prompt (5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08d0f151",
      "metadata": {
        "id": "08d0f151"
      },
      "source": [
        "**Task:** Set up the agent node with planning, tool use, and final SQL generation prompts. For writing efficient prompt you can read this link.\n",
        "https://cookbook.openai.com/examples/gpt4-1_prompting_guide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35c8f0de",
      "metadata": {
        "id": "35c8f0de"
      },
      "outputs": [],
      "source": [
        "REACT_SYS_PROMPT = \"\"\"\n",
        "#YOUR PROMPT HERE\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ee385fd",
      "metadata": {
        "id": "7ee385fd"
      },
      "source": [
        "#### Agent Node (5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0549f4b1",
      "metadata": {
        "id": "0549f4b1"
      },
      "source": [
        "**Task:** Set up the agent node with models that have binded with tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4247575c",
      "metadata": {
        "id": "4247575c"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def agent_node(state: MessagesState) -> MessagesState:\n",
        "    #For rate-limiting purposes, we will sleep for 10 seconds before invoking the LLM\n",
        "    time.sleep(10)\n",
        "    #YOUR CODE HERE\n",
        "    return state"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fe4d541",
      "metadata": {
        "id": "3fe4d541"
      },
      "source": [
        "#### Build Graph (5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39bbf177",
      "metadata": {
        "id": "39bbf177"
      },
      "source": [
        "**Task:** Assemble the ReAct agent graph, connecting the agent node and tool node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d770ec0f",
      "metadata": {
        "id": "d770ec0f"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import tools_condition\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "class ConfigSchema(TypedDict):\n",
        "    database_name: str\n",
        "\n",
        "react_builder = StateGraph(MessagesState, config_schema=ConfigSchema)\n",
        "\n",
        "#YOUR CODE HERE\n",
        "\n",
        "react_graph = react_builder.compile()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c7aee0f",
      "metadata": {
        "id": "7c7aee0f"
      },
      "source": [
        "#### Run and Evaluate (Estimated Run Time 20min)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f4a2020",
      "metadata": {
        "id": "0f4a2020"
      },
      "source": [
        "**Task:** Execute the ReAct agent pipeline on the dataset and collect SQL outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9184c4c",
      "metadata": {
        "id": "a9184c4c"
      },
      "outputs": [],
      "source": [
        "from method_run import run_method\n",
        "import re\n",
        "def run_react_agent_with_config(item):\n",
        "    question = item['question']\n",
        "    schema = item['schema']\n",
        "    user_prompt = f\"Question: {question}\\nSchema: {schema}\"\n",
        "    input_msg = HumanMessage(content=user_prompt)\n",
        "    input_config = {\"configurable\": {\"database_name\": item['db_id']}}\n",
        "    response = react_graph.invoke(MessagesState(messages=[input_msg]), config=input_config)\n",
        "\n",
        "    for msg in response[\"messages\"]:\n",
        "        msg.pretty_print()\n",
        "\n",
        "    # If last AI Message is a list of messages, we need to extract the last one\n",
        "    last_msg = response[\"messages\"][-1].content\n",
        "    if isinstance(last_msg, list):\n",
        "        last_msg = last_msg[-1]\n",
        "\n",
        "    # First try to extract query from markdown SQL block\n",
        "    match = re.search(r'```sql\\n(.*?)```', last_msg, re.DOTALL)\n",
        "    if match:\n",
        "        query = match.group(1).strip()\n",
        "    else:\n",
        "        # If no markdown block found, try to extract just SQL query\n",
        "        query = last_msg.strip()\n",
        "        # Remove any ```sql or ``` if present without proper formatting\n",
        "        query = re.sub(r'```sql|```', '', query).strip()\n",
        "\n",
        "    return {**item, 'sql': query}\n",
        "\n",
        "#Run agent on mode=nano, it's not needed to run on full dataset\n",
        "run_method(run_react_agent_with_config, SLEEP_TIME=20, mode=\"nano\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
